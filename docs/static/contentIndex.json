{"blockchain/Builder-Markets":{"title":"Builder Markets","links":[],"tags":[],"content":"Useful links\nPost-merge, independent stakeholders are\n\nSearchers\nBuilders\n\nDecentralisation of the builder market  talks about the difficulty of bootstrapping a builder, with access to private order flows and gaining market share being a chicken and egg problem. As of March 2024, builders need to subsidise their bids by around around 1.4 ETH to gain 1% market share for a week. The high barrier to entry leads to builder centralisation.\nBuilder Dominance and Searcher Dependence talks about\nHow SUAVE can address builder centralisation talks about\n\n\nRelay\nProposers\n\nSearchers\nCompetitive sandwich searchers (speed is required) use leading zeros because it speeds it up, except for jared, who probably use some other tricks to be so fast.\nTransaction Fees\nBolded terms are those you seen in etherscan. monospace terms are those in code.\nTransaction:\n\nBlock:\n\nEvery smart contract execution will consume some gas. Gas is a unit of computation, and it’s priced manually by humans (EF decides how much computational resources each opcode consumes). It is purely a function of your code execution, and nothing about bidding. A simple transfer takes 21k gas. When anyone (searcher or user) sends a tx, they can specify a gas limit/gas_limit. If the smart contract consumes more gas than the gas limit, it will revert. How much the tx actually uses is shown in etherscan as usage by txn. Gas usage is purely due to execution, nothing to do with bidding or consensus.\nNow, you need to pay for the gas your tx consumed. And this gas price is the one that changes according to various consensus factors. Note gas price has units of eth/gas, or gwei/gas. This is displayed as gas price in etherscan. The total transaction fee = gas price x usage by tx.\nHow is gas price calculated? After EIP1559, when users send tx, they send a gas fee (max priority)/max_priority_fee_per_gas, indicating how much they are willing to pay for priority gas fee (given to proposer). And they also send a gas fee (max)/max_fee_per_gas, indicating how much they are willing to pay for total gas fee. How much they are willing to pay for the gas fee (base) is intuitively = gas fee (max) - gas fee (max priority).\nBase fee per gas is decided by network congestion (if previous block maxed out gas limit). Base fee per gas is for the entire block. If the gas used maxes out the gas limit for this block, the next block will see a 12.5% increase in base fee per gas.\nThe user’s base fee per gas x gas used is burned, as seen in etherscan as burnt fees.\nBuilders\nBuilders can steal MEV, but that would lead to loss of trust.\n\nWe get a chain where block production is still centralized, but block validation is trustless and highly decentralized, and specialized anti-censorship magic prevents the block producers from censoring. - Vitalik in vitalik.eth.limo/general/2021/12/06/endgame.html\n\nvita blog talks about\nhackmd.io/@mastercow/MEVBlocker-rules refund\narxiv.org/pdf/2305.19150 centralising effects\netherscan.io/tx/0x28ce4fff4b2ec5a0274cfa1f58132ecf0ea583681ededc6917c45aa3201c33fc  why doesnt this have priority fee? because it’s not a finalised block, susceptible to reorgs\netherscan.io/tx/0xd0797a9141636f0d8ce4c196603a6b2aa94348e2b9ad1993239591228d39f84c stuck because too little gas price\nUseful links\nmevboost.pics/ nice diagram of order flows from builders ⇒ relays ⇒ validators\npayload.de/data/ bidding in real time\nReach out to me at @codfish1 :)"},"index":{"title":"index","links":["old-blogs-(jekyll)/2023-01-31-teaching-qft","blockchain/Builder-Markets"],"tags":[],"content":"2023-01-31-teaching-qft meow\nBuilder Markets"},"old-blogs-(jekyll)/2023-01-31-minimal-kernel":{"title":"Compiling and Running a Minimal Kernel with Busybox","links":["downloads/minimal.config"],"tags":[],"content":"The exploration logs are found at here.\nBuilding the Kernel\nOf course the small kernel must still be functional, so we will test it using qemu. One can also use virtualbox but I chose qemu because I will be working remotely using SSH and VNC takes too much mobile data lol.\n$ git clone git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git --depth 1 --branch v6.1.4\n$ cd linux\n$ git log\ncommit 2cb8e624295ffa0c4d659fcec7d9e7a6c48de156 (grafted, HEAD, tag: v6.1.4)\n    Author: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;\n        Date:   Sat Jan 7 11:12:04 2023 +0100\n\tLinux 6.1.4\n$ apt install -y libncurses5 libncurses5-dev bison flex\n$ make menuconfig \n# go enable PVH if u want to run in QEMU\n$ vim .config # remove &quot;debian&quot; things, and the &quot;certs/signing_key.pem&quot;\n$ apt install -y libssl-dev libelf-dev\n$ make -j$(nproc) # change -jN to your liking\n# if they prompt something involving certs, just press enter (default choices)\nImportant: Don’t forget to enable CONFIG_PVH=y in .config if you want to run in QEMU.\n$ ls -lh vmlinux\n\nvmlinux should exist, if it doesn’t, something went wrong and go back to build.\nOtherwise, let’s run our kernel!\nRunning in QEMU\nWe need an Initrd?\nWhat’s Init RAM Disk?\nIt is the first thing that the kernel looks for when it wakes up.\nYou can try the following command and see it complain that it was unable to find an init.\n$ qemu-system-x86_64 -kernel ./vmlinux -nographic --append &quot;console=tty0 console=ttyS0 panic=1 root=/dev/sda rootfstype=ext2&quot; -hda rootfs.ext2 -m 1024 -vga none -display none -serial mon:stdio -no-reboot \n# Some kernel logs before we see\n[    1.512696] Run /sbin/init as init process\n[    1.513360] Run /etc/init as init process\n[    1.513575] Run /bin/init as init process\n[    1.513772] Run /bin/sh as init process\n[    1.514056] Kernel panic - not syncing: No working init found.  Try passing init= option to kernel.\n\nThe kernel was frantically looking for an init executable in /sbin,/etc,/bin. Really just any executable (can be a shell script, or a binary executable).\nOur own init\nLet’s write our own init for now. The sleep is to prevent the kernel from panicing (it will panic if init exits).\n$ mkdir vfs &amp;&amp; cd vfs\n$ cat &lt;&lt; EOF &gt; hello-kernel.c\n#include &lt;stdio.h&gt;\n\nint main(){\n        printf(&quot;Hello, kernel!\\n&quot;);\n        sleep(9999999999999);\n}\nEOF\n$ gcc --static hello-kernel.c -o init\n\nNow we just need to package it up into a cpio format.\n$ find . | cpio -o -H newc | gzip &gt; root.cpio.gz\n\nThen we can run QEMU successfully\n$ qemu-system-x86_64 -kernel ./vmlinux -nographic --append &quot;console=tty0 console=ttyS0 panic=1 root=/dev/sda rootfstype=ext2&quot; -hda rootfs.ext2 -m 1024 -vga none -display none -serial mon:stdio -no-reboot -initrd initrd/root.cpio.gz\n[    1.461412] x86/mm: Checked W+X mappings: passed, no W+X pages found.\n[    1.461651] Run /init as init process\nHello, kernel!\n[    1.946056] tsc: Refined TSC clocksource calibration: 3399.960 MHz\n[    1.946430] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x3102293934f, max_idle_ns: 440795316s\n[    1.946791] clocksource: Switched to clocksource tsc\n\nGreat! But now we don’t just want our init to say hello, we want our init to be able to put us into a shell and let us navigate and do productive work! That is where busybox comes in!\nBusybox\nGit clone and compile Busybox\n$ cd .. # don&#039;t do stuff in the linux directory, git will be confused\n$ git clone --depth=1 github.com/mirror/busybox.git &amp;&amp; cd busybox\n$ make defconfig \n$ vi .config # set CONFIG_STATIC=y\n$ make -j$(nproc)\n$ make CONFIG_PREFIX=$PWD/BUSYBOX install\n$ ls BUSYBOX \nbin  linuxrc  sbin  usr\n\nThen we make out initrd with busybox\n$ cd ../linux # return back to linux directory\n$ mkdir initrd &amp;&amp; cd initrd # like vfs (from previously), this will house our new initrd\n$ mkdir etc proc sys\n$ cat &lt;&lt; EOF &gt; init                              \n#!/bin/sh\n                           \nmount -t proc proc /proc\nmount -t sysfs none /sys\n                                                      \n# busybox.net/FAQ.html#job_control\n                                                      \nmknod /dev/ttyS0 c 4 64\nsetsid sh -c &#039;exec sh &lt;/dev/ttyS0 &gt;/dev/ttyS0 2&gt;&amp;1&#039;\nEOF                                                   \n$ chmod +x init \n\nThe above init shell script will be our entrypoint\n$ cp ../../busybox/BUSYBOX/* . # copy over our compiled busybox utilities\n$ find . | cpio -o -H newc | gzip &gt; root.cpio.gz # package it\n\nBasically, init will call our busybox utilities! Internally, /bin/ls is a symlink to /bin/busybox ls\nFun fact: Alpine linux uses busybox, Alpine linux is popular in docker containers due to it’s small size.\nBooting\n$ qemu-system-x86_64 -kernel ./vmlinux -nographic --append &quot;console=tty0 console=ttyS0 panic=1 root=/dev/sda rootfstype=ext2&quot; -hda rootfs.ext2 -m 1024 -vga none -display none -serial mon:stdio -no-reboot -initrd initrd/root.cpio.gz \n\nWe should be dropped into a shell and now we can type busybox to see the commands we can use.\nRunning the Kernel on Hardware\nIf you’re on ubuntu, you can replace your current kernel (uname -r) with the one you compiled\n$ update-grub2 # make sure you&#039;re using the grub bootloader\n$ make modules_install\n$ make install\n\nWhen booting up, press and hold &lt;Shift&gt; to go to the grub menu, then go to advanced options to select the kernel you want to boot with.\nMinimizing the Kernel Size\nLet’s try to compile a kernel that is as small as possible.\nMeasuring Size\nThe kernel size can be determined using\n$ ls -lh vmlinux\n-rwxr-xr-x 1 tch tch 1.1G Jan 31 16:19 vmlinux\nIn this case, I will measure the size of vmlinux instead of vmlinuz since compression is cheating.\nUsing the default, we get a size of 1103946480 or 1.1G.\nMy Personal Best\nI managed to get it down to 51M with this config.\nls -lh vmlinux\n-rwxrwxr-x 1 tch tch 51M Feb  4 11:49 vmlinux\n\nTheoretically it should be able to get down to around 10M as that is what I saw on some embedded linux forums. But I have other projects on hand that require my immediate attention, I’ll come back to it one day…\nHappy Coding!\nIf you run into any errors, you may drop me a text on telegram!"},"old-blogs-(jekyll)/2023-01-31-teaching-qft":{"title":"Teaching Quantum Field Theory","links":["downloads/TanChienHao_Slides.pdf"],"tags":[],"content":"I’ve started trying to teach quantum field theory casually. The lessons take place roughly fortnightly (every Sunday 8pm on Zoom). Contact me on telegram to sit in! Hopefully I can get enough practice and refine my material such that when I am actually required to teach QFT in a university, I will be confident enough to be a good lecturer!\nHere are the slides\nand recordings (TODO to be uploaded).\nSpecial thanks to Victoris.org for supporting my lessons!"},"old-blogs-(jekyll)/2023-02-19-propagator":{"title":"Propagators in Massive Scalar Field Theory (Poster)","links":["downloads/propagator.pdf"],"tags":[],"content":"I have prepared a poster that evaluates the propagators for Retarded Propagator, Advanced Propagator, and Feynman Propagator. Enjoy!"},"old-blogs-(jekyll)/2023-02-22-Tphi-OPE":{"title":"Operator Product Expansion for $T\\phi$","links":["downloads/Tphi_OPE.pdf"],"tags":[],"content":"I have worked out in great detail the OPE. PDF"},"old-blogs-(jekyll)/2023-02-27-weylanomaly":{"title":"Why $D=26$ in Bosonic String Theory","links":["downloads/weylanomaly.pdf"],"tags":[],"content":"I am taking a string theory module in NUS this semester. For my midterms, I have prepared a presentation explains the why bosonic string theory needs 26 dimensions for “the math to make sense”. Enjoy!\nAbstract:\nIn summary, to quantise the Polyakov action for a bosonic string,\nwe had to insert the Faddeev-Popov determinant into the path\nintegral, which ended up being calculated by the bc ghost CFT. bc\nCFT alone had central charge of −26, but we need the total\ncentral charge of Polyakov + bc to be 0 due to the Weyl anomaly.\nSo the Polyakov action needed to have a ”critical central charge”\nof 26, which corresponded to the coordinates of the string being\n26-dimensional.\nThere are other ways to derive the critical dimension, such as using Lorentz invariance.\nUpdate: Here is a recording"},"old-blogs-(jekyll)/2023-02-28-susy":{"title":"Counting Supersymmetry Generators","links":[],"tags":[],"content":"We primarily see 2 types of notation\n\\mathcal{N}=(2,2) and \\mathcal{N} = 2. The ambiguity is resolved by considering the spacetime dimensions we are working in. David Tong’s notes on supersymmetry has a chapter “Counting Supersymmetries” which explains this in greater detail. I aim to summarise.\n”Spinor supercharges” vs “Supersymmetry Generators/Supercharge”\nQ^I_\\alpha (collecting the \\alpha components into a column vector) is said to be a spinor supercharge. Index I goes from 1,...,(\\mathcal{N} \\text{ or } L \\text{ or } R) (more on this ambiguity later), and index \\alpha goes from 1,...,\\text{dim of Weyl spinor representation in dim }D. Each component of the spinor supercharge is a SUSY generator. SUSY generators are also called supercharges confusingly. Therefore I find it important to state whether a quantity is a “spinor supercharge” or a “supercharge”. A spinor supercharge consists of a few component supercharges. Actually, I prefer to use supercharge to exclusively mean “spinor supercharge” and use “SUSY generator” to mean the individual components.\nWe use N (non-curly N) to denote the number of SUSY generators. And \\mathcal{N} (mathcal N) to denote the number of spinor supercharges.\n\\mathcal{N} = (L,R) vs \\mathcal{N} = n\nAnd then we see things like \\mathcal{N} = (2,2) vs \\mathcal{N} = 1. What’s going on? Again Tong’s notes explains it well.\nIn dimensions D \\equiv 2 \\text{ mod } 4, left and right handed Weyl spinors are NOT related by complex conjugation, meaning that we can have a left handed spinor supercharge without corresponding right handed spinor supercharge. That is why we use 2 numbers to describe   the number of spinor supercharges, each one being possible left or right handed.\nOn the contrary, in D\\equiv 0 \\text{ mod } 4, left and right handed spinors are related by complex conjugation. They come in pairs. Existence of left implies existence of right and vice versa. Hence one number describes the number of spinor supercharges. If we wanted to express \\mathcal{N} = n in terms of (L,R) notation, it would be (n,n).\nSo if you see something like (L,R), \\text{dim }D, the number of SUSY generators are N=(L+R)\\times (\\text{dim of Weyl spinor representation in dim }D).\nAnd if you see something like \\mathcal{N}, \\text{dim }D, the number of SUSY generators are N=\\mathcal{N} \\times 2 \\times (\\text{dim of Weyl spinor representation in dim }D).\nI have a question: What happens in odd dimensions?\nSome Examples\nThe following examples are taken from David Tong “Counting Supersymmetries” Chapter.\nN=32:\n\n\\mathcal{N} = 1, D=11\nThe spinor representation in 11 dimensions consists of 16 component generators. So N=32 is obtained by \\mathcal{N} \\times 2 \\times 16.\n\\mathcal{N} = (1,1), D=10\nThe spinor representation in 10 dimensions consists of 16 component generators. So N=32 is obtained by (L+R) \\times 16.\n\\mathcal{N} = (2,2), D=6\nThe spinor representation in 6 dimensions consists of 8 component generators. So N=32 is obtained by (L+R) \\times 8.\n\\mathcal{N} = 8, D=4\nThe spinor representation in 4 dimensions consists of 2 component generators. So N=32 is obtained by \\mathcal{N} \\times 2 \\times 2.\n\nN=16:\n\n\\mathcal{N} = (1,0), D=10 (check yourself)\n\\mathcal{N} = (1,1), D=6 (check yourself)\n\\mathcal{N} = 4, D=4 (check yourself)\n\\mathcal{N} = 8, D=3\nThe spinor representation in 3 dimensions consists of 1 component generators. So N=16 is obtained by \\mathcal{N} \\times 2 \\times 1.\n\\mathcal{N} = (8,8), D=2\nThe spinor representation in 2 dimensions consists of 1 component generators. So N=16 is obtained by (L+R) \\times 1.\n\nN=8\n\n\\mathcal{N} = (1,0), D=6 (check yourself)\n\\mathcal{N} = 2, D=4 (check yourself)\n\\mathcal{N} = 4, D=3 (check yourself)\n\\mathcal{N} = (4,4), D=2 (check yourself)\n\nN=4\n\n\\mathcal{N} = 1, D=4 (check yourself)\n\\mathcal{N} = 2, D=3 (check yourself)\n\\mathcal{N} = (2,2), D=2 (check yourself)\n\nN=2\n\n\\mathcal{N} = 1, D=3 (check yourself)\n\\mathcal{N} = (2,0), D=3\n(check yourself) This arises from twisting, and we usually say (0,2) to avoid confusion with the (2,0), D=6 theory\n\\mathcal{N} = (1,1), D=2 (check yourself)\n\nWeyl Spinor Representation\nThis can be understood by reading Clifford Algebra."},"old-blogs-(jekyll)/2023-03-06-ssl":{"title":"Setting Up SSL Manually on Kubernetes Traefik: ACME DNS Challenge","links":[],"tags":[],"content":"Btw, I will guide you in setting up SSL for any site for $25 (around 1h meeting online), contact me at @tch1001 and save yourself alot of pain in the ass :)\nToday, I will show you how to setup SSL on Kubernetes the manual way. I will be using Traefik as the Ingress Controller and Let’s Encrypt as the Certificate Authority.\nKubernetes Setup\nSuppose we have created a service (with accompanying deployment, pods, and all that) called my-service and we want to expose it to the internet.\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\nspec:\n  selector:\n    matchLabels:\n      app: my-webserver\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: my-webserver\n    spec:\n      containers:\n      - name: my-container\n        image: username/my-image\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: my-webserver\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8000\n#      nodePort: 30002\n  type: ClusterIP\n\nWe can expose it to the internet by creating an IngressRoute resource. (Note: This is not the final version)\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: my-ingressroute\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`my.domain.com`)\n      priority: 1000\n      kind: Rule\n      services:\n        - name: my-service\n          port: 80\n          namespace: my-namespace\n\nThen over on your DNS provider, you just need to point my.domain.com to your Traefik Service’s External IP address, which you can obtain using\n&gt; kubectl get svc -A # -A for all namespaces\nNAME         TYPE          CLUSTER-IP       EXTERNAL-IP       PORT(S)                   AGE\ntraefik      LoadBalancer  10.245.211.251   137.184.250.51    80/TCP,8080/TCP,443/TCP   20d\nmy-service   ClusterIP     10.245.210.243   &lt;none&gt;            80/TCP                    20d\n\nTraefik will point to my-service through the IngressRoute, and you can check the ingressroutes by going to http://&lt;traefik-service-ip&gt;:8080/dashboard/#/http/routers.\nAfter adding a DNS record (note: use DNS only first (if you’re using Cloudflare), we will get to SSL later)  \n\nGoing to my.domain.com will show you the website (note the http, we have not setup SSL yet).\nSetting up SSL\nThere are 2 different ways I will cover. The first being significantly easier but not without some drawbacks.\nBless Cloudflare (Flexible SSL)\nIf you’re using cloudflare, you’re in luck, because you just need to use “Proxied” instead of “DNS only” and you’re done. \n\nNote: If you run into errors, chances are that caching is the issue. I haven’t figured out where this caching occurs exactly. What I do is just create a new record, using a different domain name (e.g. my.domain.com and my2.domain.com).\nThis is known as a “Flexible SSL Setup”, where the SSL is terminated at Cloudflare’s edge servers. This means that the traffic between the browser and Cloudflare is encrypted, but the traffic between Cloudflare and your site is not. This is okay for non-security-critical applications like blogs, but is not okay for things that require sensitive traffic like login credentials.  \n\nThis is the easiest way to setup SSL, but another drawback is you will not be able to use HTTP/2, which is a newer version of HTTP that is much faster than HTTP/1.1. This is because Cloudflare does not support HTTP/2 for Flexible SSL. If you want to use HTTP/2, you will need to use a different method.\nOne upside is that using “Proxied” will hide your server’s IP address (increased security), and you can check this by running\n&gt; ping my2.domain.com\nPING my2.domain.com (104.21.39.182): 56 data bytes\n64 bytes from 104.21.39.182: icmp_seq=0 ttl=49 time=84.412 ms\n\n104.21.39.182 is not my IP! It is Cloudflare’s IP.\nCertbot SSL Setup\nIf you want to use “DNS only” and still have SSL, or you want “Proxied” with Full encryption mode, you need to create a certificate using Certbot. Certbot is a free, open-source tool for automatically using Let’s Encrypt certificates on manually-configured HTTPS servers.\nUsually, people use certbot because it’s very automatic, but in this case I have chosen to manually obtain my certificates and upload it because I want to learn how it works, and have greater control over the process. I have found that when I try to do it automatically using Traefik, there is a lot of fiddling and restarting the services, possibly resulting in downtime.  Through the manual method, you don’t need to touch the my-service Service, and just need to update the IngressRoutes.\nFirst, you need to install certbot. After that you can run\nsudo certbot certonly --manual --preferred-challenge dns -d my3.domain.com\n\n\n--manual is required if we want to use the DNS acme challenge.\n-d my3.domain.com indicates the domain (leaving it out will prompt you to input it manually).\n\nYou will see something like\nPlease deploy a DNS TXT record under the name:\n_acme-challenge.my3.domain.com\nwith the following value:\nNaeXRxo_oQnpUzeZQ1xj3mhSGaAJ_NXN0wTcOo-_wdA\n\nBefore continuing, verify the TXT record has been deployed. Depending on the DNS\nprovider, this may take some time, from a few seconds to multiple minutes. You can\ncheck if it has finished deploying with aid of online tools, such as the Google\nAdmin Toolbox: toolbox.googleapps.com/apps/dig/#TXT/_acme-challenge.my3.domain.com.\nLook for one or more bolded line(s) below the line &#039;;ANSWER&#039;. It should show the\nvalue(s) you&#039;ve just added.\n\nPress Enter to Continue\n\nYou need to create a TXT record with the value NaeXRxo_oQnpUzeZQ1xj3mhSGaAJ_NXN0wTcOo-_wdA under _acme-challenge.my3.domain.com. Then check using Google Admin Toolbox (toolbox.googleapps.com/apps/dig/#TXT/_acme-challenge.my3.domain.com.) whether the TXT record is up. If it is, then press Enter\nSuccessfully received certificate.\nCertificate is saved at: /etc/letsencrypt/live/my3.domain.com/fullchain.pem\nKey is saved at:         /etc/letsencrypt/live/my3.domain.com/privkey.pem\nThis certificate expires on 2023-06-04.\nThese files will be updated when the certificate renews.\n\nNow we need to upload it to Kubernetes and let IngressRoute access it. This is done via Secrets.\nmkdir certs\nsudo cat /etc/letsencrypt/live/my3.domain.com/fullchain.pem &gt; certs/fullchain.pem\nsudo cat /etc/letsencrypt/live/my3.domain.com/privkey.pem &gt; certs/privkey.pem\n# do the above if you can&#039;t access /etc\nsudo kubectl create secret generic my-secret \\\n    --from-file=tls.crt=/etc/letsencrypt/live/my3.domain.com/fullchain.pem \\\n    --from-file=tls.key=/etc/letsencrypt/live/my3.domain.com/privkey.pem\n\nAll that remains is to update the IngressRoute.\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: my-ingressroute\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`my3.domain.com`)\n      priority: 1000\n      kind: Rule\n      services:\n        - name: my-service\n          port: 80\n          namespace: my-namespace\n  tls:\n    secretName: my-secret\n    domains:\n    - main: my3.domain.com\n      sans:\n      - blah.com\n\nThe Host(`my.domain.com`) changed to Host(`my3.domain.com`) and added part is\n  tls:\n    secretName: my-secret\n    domains:\n    - main: my3.domain.com\n      sans:\n      - blah.com\n\nNow add the DNS record for my3.domain.com, change your encryption mode to “Full” and visit the site and all should be good!\nSANS is just alternative DNS names.\nSetting HTTP redirection to HTTPS\nGreat so now if you visit the site my3.domain.com you get a nicely secured site! But if you visit my3.domain.com you get 404 error. Oh no. The fix is simple, simply create another IngressRoute that accepts the - web entrypoint, and use a redirection middleware.\napiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: redirection-middleware\nspec:\n  redirectScheme:\n    scheme: https\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: my-ingressroute-no-tls\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`my3.domain.com`)\n      priority: 1000\n      middlewares:\n        - name: redirection-middleware\n      kind: Rule\n      services:\n        - name: my-service\n          port: 80\n          namespace: my-namespace\n\nCommon errors\nToo many redirects\nMost likely your SSL encryption mode is “Off” in Cloudflare.\n404\nMost likely your SSL encryption mode is “Flexible”. Cloudflare is trying to access the non-SSL version of your site while your site is forcing it to use SSL (redirecting it to https, which confuses Cloudflare).\n502 Bad Gateway\nIt could also be that your encryption mode is “Full” or “Full (Strict)” but the SSL on your Kubernetes Traefik end is not setup properly. Cloudflare is trying to establish an encrypted connection with Traefik but Traefik can’t provide one. Check that your Service is running too (can be done using NodePort on Kubernetes, or port-forward tunneling).\nStill not working :(\nTry setting up on a different domain name. I know that’s dumb but it seems like either the browser or some intermediate server along the way has cached the SSL settings. In other words, when working with SSL, you either get it the first time round or you never get it (because updating the configs don’t seem to affect much).\nWhat I do personally is try out a bunch of test domains first, before finding out the process that works for the actual one.\nRenewing\nBy manual provisioning method, the certificates will not auto-renew. I will write another blog on this when I have time."},"old-blogs-(jekyll)/2023-03-14-rbac":{"title":"Adding Users to Kubernetes (RBAC)","links":[],"tags":[],"content":"Btw, I offer hosting services (FREE if your project is open source and I like it!) and DevOps setup for small businesses or personal projects! Contact me on telegram @tch1001 any time for best web hosting practices!\nIntroduction\nWhy add users to Kubernetes? There are 2 main reasons.\nSecurity\nYou work in a big team of developers. You’re the techlead so it’s your job to make sure that the team doesn’t mess up the cluster. You can’t just give everyone admin access. So you need to create a user for each developer. This way, junior developers will not be able to singlehandedly bring down production (that’s the job of senior developers!). And you can revoke access if someone leaves the company.\nCI/CD\nWhile I was setting up CI/CD, I ran into a need to add users. I rent a managed DigitalOcean Kubernetes cluster for my personal projects. It uses doctl for authentication. Namely, in the kubeconfig file,\nusers:\n- name: do-sgp1-test-admin\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1beta1\n      args:\n      - kubernetes\n      - cluster\n      - kubeconfig\n      - exec-credential\n      - --version=v1beta1\n      - --context=k8_testing\n      - REDACTED \n      command: doctl\n      env: null\n      interactiveMode: IfAvailable\n      provideClusterInfo: false\nIf I copied this kubeconfig file to GitHub actions, it would fail because GitHub actions doesn’t have doctl installed in the GH actions runner. So I needed to add a user to the cluster that uses a key and cert instead of doctl.\nCreating a Private Key and CSR\nFirst, we need to create a private key and a certificate signing request (CSR). The CSR will be signed by the Kubernetes cluster to create a certificate. The certificate will be used to authenticate the user.\nPrivate Key\nopenssl genrsa -out tom.key 2048\n# note whatever comes after CN= (CN stands for Common Name) will be the username of the user in kubernetes\nopenssl req -new -key tom.key -out tom.csr -subj &quot;/CN=tom&quot;\nCertificate Signing Request (CSR)\nSelf Hosted Kubernetes\nNote that if you host your own kubernetes cluster and have direct SSH access to the master node, you can sign it manually using\nopenssl x509 -req -in tom.csr \\\n  -CA /etc/kubernetes/pki/ca.crt \\\n  -CAkey /etc/kubernetes/pki/ca.key \\\n  -CAcreateserial \\\n  -out tom.crt -days 500\nManaged Kubernetes\nOtherwise, you don’t have direct access to the CA cert so you have to create a CSR to send to the Kubernetes cluster via kubectl.\n$ cat tom.csr | base64 | tr -d &#039;\\n&#039;\nREDACTED_CSR_IN_BASE64\nThen, create a file called tom-csr.yaml with the following contents\napiVersion: certificates.k8s.io/v1\nkind: CertificateSigningRequest\nmetadata:\n  name: tom-csr\nspec:\n  groups:\n  - system:authenticated\n  # I found that using $(cat tom.csr | base64 | tr -d &#039;\\n&#039;) doesn&#039;t work\n  # so I just copy pasted the output of the command above\n  request: REDACTED_CSR_IN_BASE64\n  signerName: kubernetes.io/kube-apiserver-client\n  usages:\n  - digital signature\n  - key encipherment\n  - client auth\nAfter that send it to the Kubernetes API server\n$ kubectl apply -f tom-csr.yaml\n$ kubectl get csr\nNAME        AGE   SIGNERNAME                            REQUESTOR               REQUESTEDDURATION   CONDITION\ntom-csr     68m   kubernetes.io/kube-apiserver-client   your-email@gmail.com    &lt;none&gt;              Pending\nApprove the CSR\nNow we have to tell Kubernetes to approve the CSR and give us a certificate.\n$ kubectl certificate approve tom-csr\n$ kubectl get csr\nNAME        AGE   SIGNERNAME                            REQUESTOR               REQUESTEDDURATION   CONDITION\ntom-csr     68m   kubernetes.io/kube-apiserver-client   your-email@gmail.com    &lt;none&gt;              Approved,Issued\n$ k get csr testuser-authentication -o jsonpath=&#039;{.status.certificate}&#039; | base64 -d &gt; tom.crt \nAdd it to a context\nIf you manage multiple clusters (or have multiple users in a cluster), you will be comfortable with the KUBECONFIG file.\nThe most common way of using KUBECONFIG is to set the KUBECONFIG environment variable to the path of the kubeconfig file.\n$ KUBECONFIG=/path/to/kubeconfig kubectl get node\nNAME                      STATUS   ROLES    AGE   VERSION\nnode-default-pool-mk771   Ready    &lt;none&gt;   70d   v1.70.3\nnode-default-pool-mk772   Ready    &lt;none&gt;   70d   v1.70.3\n$ KUBECONFIG=/another/kubeconfig kubectl get node \nNAME                      STATUS   ROLES    AGE   VERSION\nsome-other-pool           Ready    &lt;none&gt;   10d   v1.70.2\nA convenient way to manage kubenetes contexts is to use kubectx.\nThe caveman way to edit kubeconfig files is to use vim. A more civilised way is to use kubectl config.\n$ kubectl config get-contexts\nCURRENT NAME         CLUSTER         AUTHINFO     NAMESPACE\n*       ctx-name     cluster-name    authinfo     default\n        ctx-2        cluster-name    authinfo-2   other-namespace\n# if you didn&#039;t do --embed-certs then it will be a file path, which might cause portability issues (when copying it to CI/CD, for instance)\n$ kubectl config set-credentials tom --client-key=tom.key --client-certificate=tom.crt --embed-certs=true\n# if you don&#039;t set the namespace, it will default to the namespace in the current context\n# namespace could be a source of errors! (see section below on errors)\n$ kubectl config set-context tom-context --cluster cluster-name --user=tom --namespace=tom-namespace\nContext &quot;tom-context&quot; modified.\n$ kubectl config get-contexts\nCURRENT NAME         CLUSTER         AUTHINFO     NAMESPACE\n*       ctx-name     cluster-name    authinfo     default\n        ctx-2        cluster-name    authinfo-2   other-namespace\n        tom-context  cluster-name    tom          tom-namespace\n$ kubectl config use-context tom-context\n$ kubectl config current-context \ntom-context\nAwesome! so we have created our user. But unfortunately he can’t do anything at the moment\n$ kubectl get pods\nError from server (Forbidden): nodes is forbidden: User &quot;tom&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; at the cluster scope\n\nWe need to give him some permissions using roles and role bindings.\nCreate Role and Role Binding\nThere is also a ClusterRole and ClusterRoleBinding but we will stick to Role and RoleBinding for now. It’s more or less similar too just that ClusterRole and ClusterRoleBinding are cluster scoped while Role and RoleBinding are namespace scoped.\nSwitching back to admin\nWe can’t create roles and role bindings as tom, so we have to switch back to the admin context\n$ kubectl config use-context ctx-name\n$ kubectl config current-context \nctx-name\nRole\nkubectl create role developer --verb=create --verb=get --verb=list --verb=update --verb=delete --resource=pods --resource=pods/exec --resource=pods/attach\nRole Binding\nkubectl create rolebinding tom-rolebinding --role=developer --user=tom\nTesting\n$ kubectl config use-context tom-context\n$ kubectl config current-context \ntom-context\n$ kubectl get pods\nNAME                                     READY   STATUS    RESTARTS      AGE\nsome-prevly-created-pod-fb7dc94b-pr2x8   1/1     Running   7 (73m ago)   136m\n\nCommon Errors\nError from server (Forbidden)\nSuppose after you switched context to the newly added user, you try to run kubectl get pods and you get the following error\nError from server (Forbidden): services is forbidden: User &quot;tom&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot;\nThere are a few things to check\n\nRole Binding and Roles are namespaced. You can check which namespace you created them in using\n\nkubectl get role -A\nkubectl get rolebinding -A\nThen check that the context is bound to the correct namespace. Sometimes the namespace is not set.\nkubectl config get-contexts | less -S\nCURRENT NAME         CLUSTER         AUTHINFO     NAMESPACE\n*       ctx-name     cluster-name    authinfo     default\n        ctx-2        cluster-name    authinfo-2   other-namespace\n\nYou can check for authorization using\n\n$ kubectl auth can-i list pods --as tom\nyes\n$ kubectl auth can-i list pods --as tommy\nno\n\nCheck the Role. Stare at your previous kubectl command for a while.\n\nkubectl create role developer --verb=create --verb=get --verb=list --verb=update --verb=delete --resource=pods\n\nCheck the Role Binding. Stare at your previous kubectl command for a while. Especially the --user field. It must match the CN= in the CSR.\n\nkubectl create rolebinding testuser-authentication-rolebinding-2 --role=developer --user=tom"},"old-blogs-(jekyll)/2023-03-29-special-relativity":{"title":"SPOT Talk: Special Relativity","links":["downloads/SR_SPOT.pdf"],"tags":[],"content":"I gave a talk on motivating special relativity using math to the Singapore Physics Olympiad Team (SPOT). Here are the slides, and recording. I really enjoyed motivating things from scratch and giving such talks. Let me know what topic you want next!"},"old-blogs-(jekyll)/2023-04-27-ehresmann":{"title":"Ehresmann Connection and Gauge Theory","links":[],"tags":[],"content":"Ehressmann Connection\ntldr; Connections on Fiber bundles are are specified by vertical bundle-valued one-forms\nOne might be familiar with the connection as the Christoffel symbols {\\Gamma^\\mu}_{\\nu\\rho}(x) or the gauge field A^\\mu(x). We will review the idea of Ehresmann connection that unifies these 2 seemingly disparate structures in a more abstract framework. It is essential if we are going to generalize the Levi Civita connection (Christoffel symbols) on the tangent bundle to a spin connection on the spin bundle.\nThe Ehresmann connection can be defined for any smooth Fiber bundle \\pi: E\\rightarrow M with smooth fiber F=\\pi^{-1}(m),\\ m\\in M. If we consider tangent bundle d\\pi: TE \\rightarrow TM, one can see that \\dim T_{(m,f)} TE = \\dim E = \\dim M + \\dim F = \\dim T_m M + \\dim F, which implies that \\dim \\ker d\\pi = \\dim F. Intuitively, the tangent bundle TP has some linear subspace that are “along F”, and this leads to the definition of VE := \\ker(d\\pi: TE \\rightarrow TM)\nOne can look for another subspace that is complementary to VE, i.e.\nTE = VE \\oplus HE\nThe intuition is that vectors in HE point in a direction that leads to another fiber, while vectors in VE point in a direction tangent to the current fiber. I would love to add a diagram showing an example with \\dim M = \\dim F = 1 (the only intuitive diagram one can draw in my opinion).\nIn the absence of any additional structure, there are many valid choices of HE, and our choice of HE affects \\text{ver}(X). This is analogous to saying that the vector space of degree 2 polynomials \\text{span} (1,x,x^2) can be decomposed in many ways\n\\begin{aligned}\n\\text{analogous to }TE &amp;= VE \\oplus HE \\\\\n\\text{span} (1,x,x^2) &amp;= \\text{span} (1) \\oplus \\text{span} (x,x^2) \\quad \\quad \\Rightarrow \\text{ver}(x+1) = 1\\\\\n\\text{span} (1,x,x^2) &amp;= \\text{span} (1) \\oplus \\text{span} (x+1, x^2) \\ \\Rightarrow \\text{ver}(x+1) =0 \\\\\n\\end{aligned}\nConnection Form\nInstead of saying we provide a horizontal subspace at every tangent space of the the tangent bundle TE, it is an equivalent definition to just provide a projection map\n\\Phi : TE \\rightarrow VE\nfrom which HE = \\ker \\Phi  can be inferred.\nPunchline: One can say that \\Phi is a VE-valued one-form on E since it takes a vector in TE and gives an element of VE.\nEhressmann Connection on G-bundle\ntldr; Connection on G-bundle P is a Lie algebra-valued one-form on TP\nIf we consider E to be a principal G-bundle P, then the \\Phi:TE\\rightarrow VE is a Lie group-valued one-form. Since VE consists of vectors that live in the tangent space T_{(m,g)} E that have the same dimension as \\dim G, the vertical subspace V_{(m,g)}E \\cong T_g G \\cong T_e G \\cong \\mathfrak{g} is isomorphic to the Lie algebra. So the connection \\Phi on a G-bundle is specified by a Lie algebra-valued one-form on P (the full bundle P\\rightarrow M).\nHowever, it turns out that given a local trivialization \\mathcal{U}\\times G of P \\rightarrow M, specifying a Lie algebra-valued one-form \\omega^\\mathcal{U} : T\\mathcal{U}\\rightarrow \\mathfrak{g} on M actually specifies enough information to specify \\Phi_\\mathcal{U} on \\pi^{-1}(\\mathcal{U}), which is then glued together with other charts to obtain \\Phi on the full bundle P. This might seem wild at first since surely projecting \\Phi onto M to yield \\omega will lose information with regard to how this one form behaves on the fibers. The answer is that the condition that there is an action of G on the fibers G is constraining enough to reconstruct \\Phi given \\omega. These \\omega^\\mathcal{U} are known as the Yang-Mills fields. There are alot of details that are covered in the excellent lecture 22 by Frederic Schuller.\nDetails of Theorem\nThe main result is a theorem\n\npresented at 21:28 of Schuller Lecture 22 (I follow his notation)\nTheorem 10.1 in Nakahara\nWiki\n\nGiven a section \\sigma:\\mathcal U \\rightarrow P which induces canonical local trivialization h:\\mathcal{U}\\times G \\rightarrow P, a \\mathfrak g-valued one-form \\omega on P can be pulled back via \\sigma or h.\nThe \\sigma^* \\omega pullback induces the h^*\\omega pullback by the following definition\n h^* \\omega_{(m,g)}(v,\\gamma) := \\text{Ad}_{g^{-1}} ((\\sigma^* \\omega) (v)) + (L_{g^{-1}})_* (\\gamma)\nwhere v\\in T_m \\mathcal U,\\ \\gamma \\in T_g G.\nTheorem: This h^* \\omega satisfies the 2 properties of a connection, namely\n\n(h^* \\omega)(h^{-1}_* A^\\#) = A\n(R_g^* (h^* \\omega))(h^{-1}_* X) = \\text{Ad}_{g^{-1}} (h^*\\omega (h^{-1}_* X))\n\nwhere A \\in \\mathfrak g and A^\\#:P\\rightarrow TP is the fundamental vector field on P generated by A, defined pointwise as\n\\ A^\\#_{p\\in P} := \\left.\\frac{d}{dt} R_{\\exp(tA)} (p) \\right\\vert_{t=0} \\in V_pP \\subset T_pP\nProof of (h^* \\omega)(h^{-1}_* A^\\#) = A:\nSince A^\\# \\in V_p P, the pushforward via h yields h_* A^\\# = (0, \\gamma) \\in T_m \\mathcal U \\times T_g G, where \\gamma is\n\\gamma =\\left. \\frac{d}{dt}  g \\exp (tA) \\right\\vert_{t=0} \nwhere (m,g) = h^{-1} (p). It is clear from this that (L_{g^{-1}})_*\\gamma = A.\nThis condition is basically saying that the inverse pullback h^{-1*} h^* \\omega = \\omega satisfies the connection one-form condition \\omega (A^\\#) = A.\nProof of (R_g^* (h^* \\omega))(h^{-1}_* X) = \\text{Ad}_{g^{-1}} (h^*\\omega (h^{-1}_* X)):\nTo prove this,\n\\begin{aligned}\n\\text{LHS} &amp; = (R_k^* (h^* \\omega))(h^{-1}_* X) \\\\\n &amp; = h^* \\omega( R_{k*} h^{-1}_* X )\\\\\n&amp; = (h^* \\omega)_{(m, gk)}(v, R_{k*} \\gamma) \\\\\n&amp; = \\text{Ad}_{(gk)^{-1}} (\\sigma^* \\omega(v)) + L_{(gk)^{-1} * R_{k*} \\gamma } \\\\\n&amp; = \\text{Ad}_{k^{-1}}\\text{Ad}_{g^{-1}}(\\sigma^* \\omega(v)) + L_{k^{-1}*} R_{k*} L_{g^{-1}*}\\gamma \\\\\n&amp; = \\text{Ad}_{k^{-1}} \\left( \\text{Ad}_{g^{-1}}(\\sigma^* \\omega(v)) + L_{g^{-1}*}\\gamma \\right) \\\\\n&amp; = \\text{Ad}_{k^{-1}} \\left( h^* \\omega(h^{-1}_* X)  \\right) \\\\\n&amp; = \\text{RHS}\n\\end{aligned}\nSo the above calculations has shown that given a \\mathfrak{g}-valued one-form \\omega^\\mathcal{U} on \\mathcal{U} and a section \\sigma:\\mathcal U \\rightarrow \\pi^{-1}(\\mathcal U), there exists a unique connection one-form \\omega on \\pi^{-1}(\\mathcal U) such that \\omega^\\mathcal{U} = \\sigma^* \\omega. The constructed connection depends on \\sigma.\n\n\\Leftarrow construction: Split P into charts \\mathcal U ^ i. Then each local trivialization induces a section \\sigma_i : M \\rightarrow P. The pullback of \\omega on P via \\sigma_i will give an \\omega^\\mathcal{U_i} on \\mathcal{U}_i, which is a Yang-mills field \\omega^M on the base manifold M after gluing. The gluing is what we call “gauge transformations of A” or “how \\Gamma transforms under change in coordinates”.\n\\Rightarrow construction: Split P into charts \\mathcal U^i. On each chart, the one-form \\omega^{\\mathcal U^i} on \\mathcal U^i induces a one-form (which is actually h^* \\omega) on the local trivialisation h of \\pi^{-1}(\\mathcal U^i) via the theorem above. These h^*\\omega can be glued together to construct a one-form \\omega on P.\nClearing the Ambiguity in Nakahara’s Notation\nI learned alot from Nakahara’s book, but I find their section on connection one-form slightly ambiguous. For the connection one-form on P, they write\n\\omega_i \\equiv g_i^{-1}\\pi^* \\mathcal A_i g_i + g_i^{-1} dg_i\nwhere \\mathcal A_i is the Yang Mills one-form on the base manifold M.\nThe first term g^{-1}_i \\pi^* \\mathcal A_i g_i actually means\n\\text{Ad}_{g_i^{-1}} (\\pi^* \\mathcal A_i(X))\nwhere \\text{Ad}_{g_i^{-1}}: T_e G \\rightarrow T_e G is the adjoint action of G on \\mathfrak g, and X\\in T_p \\mathcal P. The \\text{Ad}_{g^{-1}}(Y) and g^{-1} Y g,\\ Y \\in \\mathfrak g notations coincide for matrix Lie groups, where the multiplication between g and Y is matrix multiplication. I still prefer to talk purely in non-matrix notation because I find it’s clearer.\nBecause X = H + V and V \\in \\ker \\pi^*, the above actually reduces to\n\\text{Ad}_{g_i^{-1}} (\\mathcal A_i(v))\nwhere v\\in T_m \\mathcal U^i \\cong H_p P is a horizontal vector. The first term takes care of the vertical component of X.\nThe second term is extremely ambiguous. g_i^{-1} is simply just L_{g^{-1}*}. Trouble comes from dg_i. Usually one uses dg to denote the pushforward of g. But in this case, dg actually means \\gamma \\in V_p P \\cong T_g G. If I include the implicit annotations,\n{\\omega_i}_{(m,g)} (X) \\equiv \\text{Ad}_{g_i^{-1}} (\\mathcal A_i(\\text{hor}(X))) + L_{g^{-1}*} (\\text{ver}(X))\nSo how does one justify dg = \\gamma? g is interpreted as a map \\mathbb R \\rightarrow G in the local trivialization h^{-1}(p) = (m,g). A vector is the derivative of a curve at one point of the curve, so given a curve C in P which leads to vector X=\\frac{dC}{dt}, we actually mean to define\ndg \\equiv \\frac{d}{dt} g(C(t)) \\in V_p P\ni.e. derivative of the G fiber “coordinate” of our curve C(t)=(m(t),g(t)). dg:TM\\rightarrow VP  is the pushforward of the map g:M\\rightarrow P. So dg(\\pi^*X ) = \\text{ver}(X).\ntldr; dg is \\text{ver} (X).\nGluing of Connection One-Form\nGiven 2 overlapping local trivializations \\mathcal U^i \\cap \\mathcal U^j (which induces 2 local sections \\sigma_i, \\sigma_j : \\mathcal U^i \\cap \\mathcal U^j \\rightarrow P), we would like to find how \\sigma_{i}^* \\omega is related to \\sigma_{j}^* \\omega. The answer is obtained by investigating how they act on a vector X \\in T_{m} (\\mathcal U^i \\cap \\mathcal U^j). We need to calculate \\sigma_{i*} X \\in T_{\\sigma_i(m)} P  in terms of \\sigma_{j*} X \\in T_{\\sigma_j(m)} P. Or in terms of the local trivialisation {(h_i \\circ \\sigma_i)}_{*} X \\in T_{(m, e_i)} \\mathcal U^i \\times G and {(h_j \\circ\\sigma_j)}_{*} X \\in T_{(m, e_j)} \\mathcal U^j \\times G.\nWe know that t_{ij}: \\mathcal U^i \\cap \\mathcal U^j \\rightarrow G is the transition map defined as the unique (guaranteed since G acts freely and transitively on the fibers of P) element t_{ij}(m) \\in G such that\nR_{t_{ij}(m)}(p) = h_j \\circ h_i^{-1}(p)\nThis definition can be rephrased in a more friendly manner as\n\\begin{aligned}\nh_i^{-1}(p) = &amp;\\ h_j^{-1}(p) \\bullet_R t_{ij}(m) \\\\\n\\text{Denoting } h^{-1}(p) := &amp;\\ (m, g(p)) \\text{ ,}\\\\\ng_i(p) = &amp;\\ g_j(p) \\bullet_G t_{ij}(m)\n\\end{aligned}\nRepeating the derivation with i \\leftrightarrow j swapped, we get that t_{ij} = t_{ji}^{-1}\nIf we let p=\\sigma_j(m), then the last equation becomes\ng_i(\\sigma_j(m)) = e \\bullet_G t_{ij}(m) = t_{ij}(m)\nwhich translates the definition into a statement about transition maps between sections\n\\sigma_j(m) = \\sigma_i(m) \\bullet_R t_{ij}(m)\nSuppose we have a curve \\gamma(t) in M that yields the vector T_m M \\ni X = \\frac{d\\gamma}{dt} \\vert_{t=0} at m:=\\gamma(0). This vector acts on a function f:M\\rightarrow \\mathbb R. The pushforward is given by\n\\begin{aligned}\n\\sigma_{j*}(X)(f) &amp; = \\left. \\frac{d}{dt} f[\\sigma_j (\\gamma (t))] \\right\\vert_{t=0} \\\\\n&amp; = \\left. \\frac{d}{dt} f[\\sigma_i(\\gamma(t)) \\bullet_R t_{ij}(\\gamma(t))] \\right\\vert_{t=0}\\\\\n&amp; = \\left. \\frac{d}{dt} f[\\sigma_i(\\gamma(t))\\bullet_R t_{ij}(m)] \\right\\vert_{t=0} + \\left. \\frac{d}{dt} f[\\sigma_i(m) \\bullet_R t_{ij}(\\gamma(t))] \\right\\vert_{t=0} \\\\\n&amp; = \\left. \\frac{d}{dt} (f \\circ R_{t_{ij}(m)})[\\sigma_i(\\gamma(t))] \\right\\vert_{t=0}\n+ \\left. \\frac{d}{dt} f[\\sigma_i(m) \\bullet_R \\exp(\\log t_{ij}(\\gamma(t)))] \\right\\vert_{t=0} \\\\\n&amp; = \\left( \\left. \\frac{d}{dt} \\sigma_i(\\gamma(t)) \\right\\vert_{t=0} \\right) (f \\circ  R_{t_{ij}(m)})\n+ (\\log t_{ij}(m))^\\#_{\\sigma_i(m)} f\\\\\n&amp; = R_{t_{ij}(m)*}\\left( \\left. \\frac{d}{dt} \\sigma_i(\\gamma(t)) \\right\\vert_{t=0} \\right) f\n+ \\left(L_{t_{ij}^{-1}*} \\left. \\frac{d}{dt} t_{ij}(\\gamma(t)) \\right\\vert_{t=0} \\right)^\\#_{\\sigma_i(m) \\bullet_R t_{ij}(m)} f\\\\\n&amp; = R_{t_{ij}(m)*} \\sigma_{i*} \\left( \\left. \\frac{d}{dt} \\gamma(t) \\right\\vert_{t=0} \\right) f\n+ \\left(L_{t_{ij}^{-1}*} t_{ij*}\\left. \\frac{d}{dt} \\gamma(t) \\right\\vert_{t=0} \\right)^\\#_{\\sigma_j(m)} f\\\\\n&amp; = (R_{t_{ij}(m)*} \\sigma_{i*} X) f + \\left(L_{t_{ij}^{-1}*} t_{ij*} X \\right)^\\#_{\\sigma_j(m)} f \\\\\n&amp; = \\left(R_{t_{ij}(m)*} \\sigma_{i*} X + \\left(L_{t_{ij}^{-1}*} t_{ij*} X \\right)^\\#_{\\sigma_j(m)} \\right) f \\\\\n\\end{aligned}\nso the vector fields are related as follows\n\\sigma_{j*}X = R_{t_{ij}*} (\\sigma_{i*} X) + \\left(L_{t_{ij}^{-1}*} t_{ij*} X\\right)^\\# \nNote that each term is responsible for the horizontal H and vertical V component of the vector X=H+V. Right G-invariance of the horizontal bundle R_{t_{ij}*} : H_{\\sigma_i(m)} P \\rightarrow H_{\\sigma_j(m)} P means horizontal gets mapped onto horizontal. The Y^\\# vector field generated from an element Y of the Lie algebra \\mathfrak g lives in the vertical bundle too, so vertical maps onto vertical.\nThis allows us to relate \\sigma_i^* \\omega to \\sigma_j^* \\omega, which is what we call “gauge transformations” of \\mathcal A.\n\\begin{aligned}\n\\sigma_{j}^* \\omega (X) &amp; = \\omega(\\sigma_{j*} X)\\\\\n&amp; = \\omega(R_{t_{ij}*}(\\sigma_{i*}X) + \\omega\\left((L_{t_{ij}^{-1}*} t_{ij*} X)^\\# \\right) \\\\\n&amp; = (R^*_{t_{ij}} \\omega)(\\sigma_{i*} X) + L_{t_{ij}^{-1}*} t_{ij*} X \\\\\n&amp; = \\text{Ad}_{t^{-1}_{ij}} (\\omega(\\sigma_{i*}X)) + L_{t_{ij}^{-1}*} t_{ij*} X \\\\\n&amp; = \\text{Ad}_{t^{-1}_{ij}} (\\sigma_{i}^* \\omega(X)) + L_{t_{ij}^{-1}*} t_{ij*} X \\\\\n\\end{aligned}\nSo this is the mathematically precise expression for the A \\mapsto g^{-1} A g + g^{-1} d g\nComparison with Frederic Schuller Lecture 22\nIn case you were wondering how to match the result we derived with Schuller’s Lecture 22 timestamp 59:08, where he says that\n\\omega^{\\mathcal U^{(2)}}_m = \\text{Ad}_{\\Omega^{-1}(m)} \\circ \\omega^{\\mathcal U^{(1)}} + \\Omega^* \\Xi \n\nIn our case \\omega is a \\mathfrak g-valued one-form on P whereas his \\omega is a one-form on M. So our \\sigma_j^* \\omega is his \\omega^{\\mathcal U^{(j)}}.\nHis \\Omega is our t_{ij}\nHis Maurer Cartan form \\Xi: T_g G \\rightarrow T_e G \\cong \\mathfrak g is just L_{g^{-1}*}, in this case g is \\Omega. For our expression to match his, we just rewrite L_{t_{ij}^{-1}*} (t_{ij*} X) as (t_{ij}^* L_{t_{ij}^{-1}*}) X, i.e. we pullback the \\mathfrak g-valued one-form on G L_{t_{ij}^{-1}*}:T_{t_{ij}}G \\rightarrow T_e G \\cong \\mathfrak g via t_{ij}:M\\rightarrow G to yield a \\mathfrak g-valued one-form on M t_{ij}^* L_{t_{ij}^{-1}*}:T_{m}M \\rightarrow T_e G \\cong \\mathfrak g So our t_{ij}^* L_{t_{ij}^{-1}*} is identified with his \\Omega^* \\Xi\n\n\nCalculating Christoffel Symbols\nChristoffel symbols \\Gamma is just the connection one-form \\omega:T_p M\\rightarrow \\mathfrak g on the base manifold of a tangent frame bundle (which can be shown to be a GL(d)-principal bundle). The goal will be to calculate how \\Gamma changes when we change coordinates.\nThe nice thing is that a coordinate chart x:\\mathcal U^{(1)} \\rightarrow {\\mathbb R}^d on \\mathcal U^{(1)} \\subset M already defines a local trivialization of the GL(d)-bundle. Namely, the d coordinate functions x^i: \\mathcal U^{(1)} \\rightarrow \\mathbb R can be used to define a section \\sigma^{(1)}:\\mathcal U^{(1)}\\rightarrow F(T_{\\sigma^{(1)}(x)}M)\n\\sigma^{(1)}(x) = \\left(\\frac{\\partial}{\\partial x^1}, \\frac{\\partial}{\\partial x^2},...\\ , \\frac{\\partial}{\\partial x^d}\\right) \nA vector X\\in T_p M can be written as X = X^\\mu \\partial_\\mu, with \\mu=1,...\\ ,\\dim M. Hence the “Yang-Mills” one-form on the base manifold M takes the form \\sigma^{(1)} \\omega := \\mathbf{\\Gamma}_\\mu dx^\\mu , where \\mathbf \\Gamma_\\mu \\in \\mathfrak g.\nSince G=GL(d), the Lie algebra is just \\mathfrak g = \\mathfrak{gl}(d), consisting of all d\\times d  real matrices. So \\mathbf \\Gamma_\\mu = {\\Gamma^i}_{j\\mu} where i,j=1,...\\ ,d are indices for the matrix Lie algebra \\mathfrak{gl}(d).\nWe are interested in the transformations laws for this \\Gamma. Suppose we have another chart y:\\mathcal U^{(2)} M \\rightarrow \\mathbb R^d. Then on the intersection \\mathcal U^{(1)} \\cap \\mathcal U^{(2)}, if \\gamma(t)\\in M is a curve with tangent vector X=\\dot\\gamma(0),\n\\begin{aligned}\n\\sigma_{j}^* \\omega (X) &amp;= \\text{Ad}_{t^{-1}_{ij}} (\\sigma_{i}^* \\omega(X)) + L_{t_{ij}^{-1}*} t_{ij*} X \\\\\n\\mathbf \\Gamma^{(2)}_\\mu dy^\\mu (X) &amp;= \\mathbf \\Omega^{-1} \\left( \\mathbf \\Gamma^{(1)}_\\mu dx^\\mu (X) \\right) \\mathbf \\Omega + \\mathbf \\Omega^{-1} \\left. \\frac{d}{dt} \\mathbf \\Omega(\\gamma(t)) \\right\\vert_{t=0}\n\\end{aligned}\nThe last term can be rewritten as\n\\mathbf\\Omega^{-1} \\frac{\\partial \\mathbf\\Omega(x)}{\\partial x^\\mu}  \\frac{dx^\\mu(\\gamma(t))}{dt} = \\mathbf\\Omega^{-1} \\frac{\\partial \\mathbf\\Omega(x)}{\\partial x^\\mu} X^\\mu\nSo with all the indices flashed out,\n\\begin{aligned}\n{\\Gamma^{(2) i}}_{j\\mu} dy^\\mu(X) &amp;= {(\\Omega^{-1})^i}_{k} \\left( {\\Gamma^{(1)k}}_{l\\mu} dx^\\mu (X)\\right) {\\Omega^l}_j + {(\\Omega^{-1})^i}_k\\partial_\\mu {\\Omega^k}_j X^\\mu\n\\end{aligned}\nThe vector X = X^\\mu \\frac{\\partial}{\\partial x^\\mu} expressed in the 2nd chart is X = \\tilde X^\\mu \\frac{\\partial}{\\partial y^\\mu}, with X^\\mu = \\frac{\\partial x^\\mu}{\\partial y^\\nu} \\tilde X^\\nu\nSo\ndx^\\mu(X) = X^\\mu = \\frac{\\partial x^\\mu}{\\partial y^\\nu}\\tilde X^\\nu\nPutting this back into the above expression,\n{\\Gamma^{(2) i}}_{j\\mu} \\tilde X^\\mu &amp;= {(\\Omega^{-1})^i}_{k} \\left( {\\Gamma^{(1)k}}_{l\\mu} \\frac{\\partial x^\\mu}{\\partial y^\\nu}\\tilde X^\\nu \\right) {\\Omega^l}_j + {(\\Omega^{-1})^i}_k\\partial_\\mu {\\Omega^k}_j X^\\mu\n\\end{aligned}$$\n\nNow the transition functions $\\Omega:M\\rightarrow GL(d)$, or in coordinates, ${\\Omega^i}_j: M \\rightarrow \\mathbb R$ are actually\n\n$${\\Omega^i}_j = \\frac{\\partial x^i}{\\partial y^j}$$\n\n$${(\\Omega^{-1})^i}_j = \\frac{\\partial y^i}{\\partial x^j}$$\n\nso\n\n$$\\begin{aligned}\n{\\Gamma^{(2) i}}_{j\\mu} \\tilde X^\\mu &amp;= \\frac{\\partial y^i}{\\partial x^k} \\left( {\\Gamma^{(1)k}}_{l\\mu} \\frac{\\partial x^\\mu}{\\partial y^\\nu}\\tilde X^\\nu \\right) \\frac{\\partial x^l}{\\partial y^j} + \\frac{\\partial y^i}{\\partial x^k} \\frac{\\partial^2 x^k}{\\partial y^\\mu \\partial y^j} \\tilde X^\\mu\n\\end{aligned}$$\n\nRemoving the $X$ (more rigorously, choosing $X=\\delta^{\\mu\\rho} \\frac{\\partial}{\\partial y^\\rho}$),\n\n$$\\begin{aligned}\n{\\Gamma^{(2) i}}_{j\\rho} &amp;= {\\Gamma^{(1)k}}_{l\\mu} \\frac{\\partial y^i}{\\partial x^k}  \\frac{\\partial x^\\mu}{\\partial y^\\rho}  \\frac{\\partial x^l}{\\partial y^j} + \\frac{\\partial y^i}{\\partial x^k} \\frac{\\partial^2 x^k}{\\partial y^\\rho \\partial y^j}\n\\end{aligned}$$\n\nNot all indices of $\\Gamma$ are the same type! 1 of them is spacetime, the other 2 actually label the Lie algebra.\n\n### Memorisation Trick\nWhen we learn this in GR we usually get giddy just trying to write it with the correct indices. However, if we write it as follows and compare with the abstract form, it becomes much clearer what is really going on\n\n$$\\begin{aligned}\n{\\Gamma^{(2) i}}_{j\\rho} dy^\\rho &amp;= \\frac{\\partial y^i}{\\partial x^k} \\left({\\Gamma^{(1)k}}_{l\\mu}  \\frac{\\partial x^\\mu}{\\partial y^\\rho} dy^\\rho \\right) \\frac{\\partial x^l}{\\partial y^j} + \\frac{\\partial y^i}{\\partial x^k} \\frac{\\partial}{\\partial y^\\rho } \\left(\\frac{\\partial x^k}{\\partial y^j} \\right) dy^\\rho\\\\\n\\mathbf \\Gamma^{(2)}_\\rho dy^\\rho &amp;= \\mathbf\\Omega^{-1} \\left(\\mathbf \\Gamma^{(1)}_\\mu dx^\\mu\\right) \\mathbf \\Omega + \\mathbf \\Omega^{-1} d \\mathbf \\Omega\n\\end{aligned}$$"},"old-blogs-(jekyll)/2023-04-28-covariant-derivative":{"title":"Koszul Connection and Covariant Derivative","links":["(https:/www.amazon.com/Geometry-Topology-Physics-Graduate-Student/dp/0750306068)"],"tags":[],"content":"Good Resources\n\nWiki: associated bundle, Koszul connection\nFrederic Schuller Lectures 19-25, specifically 23 for this blog\nNakahara Chapter 10.4\n\nWe mostly follow the notation in Schuller Lecture 25.\nAs part 2 of my series building towards “Twisting Supersymmetry” (see part 1 here), I will talk about connections on associated bundles induced by connections on principal bundle. We actually see this very often: U(1) gauge theory (electromagnetism) will often have a scalar field (scalar QED) or a Dirac spinor field (QED) charged under U(1). If one inspects the covariant derivative in scalar QED, it actually arises from the connection on the complex line bundle (\\mathbb C-bundle) induced by the connection on the U(1)-principal bundle. And for QED, it is the connection on the K \\oplus \\bar K vector bundle (Dirac spinor bundle) induced by the connection on the U(1)-principal bundle.\nAssociated Bundle\nLoosely speaking, an associated bundle (associated to some G-principal bundle) is a way to attach to each point in x\\in M a fiber \\pi^{-1} x \\cong F  homeomorphic to a topological space F on which G acts on. This fiber could be a Lie group G itself (so a G-principal bundle is technically associated to itself), but this definition also allows for vector spaces, which means we can have representations (\\rho, V) of G as fibers too.\nThe formal definition (wiki) is considering the direct product modulo an equivalence relation\n\\begin{aligned}\n&amp; P_V := P\\times_\\rho V := (P \\times V) / \\sim  \\\\\n&amp; (p, v) \\sim (p \\bullet_R g , g^{-1} \\bullet_L v) \n\\end{aligned}\nIntuition: it may initially seem weird that we are considering all pairs, but it turns out this equivalence relation basically collapses the entire G fiber of P to a single point in the base manifold M. So the only “degree of freedom” left is the V. So effectively we are attaching a copy of V to every point in the base manifold M.\nCovariant Derivative of Associated Bundle Section (Teaser)\nThis is the end goal: given a vector X\\in T_p M and a section in a vector bundle \\sigma: M \\rightarrow P_V (we need vector bundle structure because otherwise subtraction won’t make sense in the fiber), we want to rigorously calculate the covariant (directional) derivative of \\sigma wrt X direction\n\\nabla_X \\sigma \\vert_p \\in \\pi^{-1}(p) \\cong V\nWe want this covariant derivative to satisfy various properties, which we can check later once we have defined it. For f \\in C^{\\infty} (M),\\ T,S \\in T M\n\n\\nabla_{fT+S} \\sigma = f \\nabla_T \\sigma+ \\nabla_S \\sigma\n\\nabla_T \\sigma_1 + \\sigma_2 = \\nabla_T \\sigma_1 + \\nabla_T \\sigma_2\n\\nabla_T (f \\sigma) = T(f) \\sigma + f \\nabla_T \\sigma \n\nThe definition that we work towards is the following: for a local section s:\\mathcal U \\subset M \\rightarrow P_V, a local trivialisation \\varphi : \\mathcal U \\subset M \\rightarrow P, the exterior covariant derivative on P, and a V-valued function \\phi:P\\rightarrow V, a \\mathfrak g-valued connection one-form \\omega:P \\rightarrow \\mathfrak g\n\\nabla_T s := (\\varphi^* D \\phi) (T) = ds(T) + (\\varphi^* \\omega)(T) \\bullet_{d\\rho} s\nIt is a definition dump for now but let’s explain the details.\nExterior Covariant Derivative on P\nDefinition: For an any-valued n-form f on \\Omega^n(P),\nDf := df \\circ \\text{hor}\nSpecial case 1: if \\omega is \\mathfrak g-valued connection one-form (n=1), for any X,Y\\in TP,\nD\\omega(X,Y) := d\\omega (\\text{hor}(X), \\text{hor}(Y))\nSpecial case 2: if \\phi is a F-valued function on P (n=0), for any X\\in TP,\nD\\phi(X) := d\\phi(\\text{hor}(X))\nCorrespondence between F-valued functions on P &amp; global sections of associated bundle P_F\nOne can define the covariant derivative using parallel transport on the associated vector bundle P_V but that definition is difficult to work with. Instead we seek to define things by using the principal G-bundle P and defining objects on it, then pulling them over to the associated bundle P_V.\nWe are going to work with a general fiber F (not necessarily a vector bundle).\nThe first thing to establish is the one-to-one correspondence between (global) sections \\sigma on P_V and G-equivariance F-valued functions \\phi on P. G-equivariance means \\phi(p \\bullet_R g) = g^{-1} \\bullet_L \\phi(p)\nThe correspondence from \\sigma to \\phi_\\sigma is\n\\begin{aligned}\n\\phi_\\sigma : P &amp; \\rightarrow F \\\\\np &amp; \\mapsto i^{-1}_p (\\sigma (\\pi(p)))\\\\\n\\text{where } i_p : F &amp; \\rightarrow P_F \\\\\nf &amp; \\mapsto [(p, f)]\n\\end{aligned}\nOne can check (watch Schuller Lec 25) that this \\phi is G-equivariant\nThe other direction from \\phi to \\sigma_\\phi is\n\\begin{aligned}\n\\sigma_\\phi: M &amp; \\rightarrow P_F\\\\\nx &amp; \\mapsto [(p, \\phi(p))] \\text{ for any }p \n\\end{aligned}\nOne can check (watch Lec 25) that \\phi_{\\sigma_\\phi} = \\phi and \\sigma_{\\phi_\\sigma} = \\sigma\nExterior Covariant Derivative of \\phi:P\\rightarrow V\nOnly if we set the fiber F to be some finite dimensional vector space V (isomorphic to \\mathbb R^{\\text{dim }V}), a (left) representation of G, then the G-equivariance condition\n\\phi(p\\bullet_R \\exp(At)) = \\exp(-At) \\bullet_\\rho \\phi(p) \\quad \\forall t\\in \\mathbb{R},A\\in \\mathfrak g\ncan be differentiated (because the vector space has an addition). So fixing A\\in \\mathfrak g and differentiating wrt t,\n\\begin{aligned}\n\\left. \\frac{d}{dt}\\phi(p\\bullet_R \\exp(At)) \\right\\vert_{t=0}  &amp; = \\left. \\frac{d}{dt} \\exp(-At) \\bullet_{\\rho} \\phi(p) \\right\\vert_{t=0} \\\\\nd\\phi(X_p^{A}) &amp; = -A \\bullet_{d\\rho} \\phi(p) \\in T_{\\phi(p)} V\n\\end{aligned}\nwhere d\\phi : T_p P \\to T_{\\phi(p)} V is the pushforward of \\phi: P \\to V. The \\bullet_{d\\rho}:\\mathfrak g \\times T_v V \\rightarrow T_v V action is the pushforward of the Lie group representation. Actually to be more precise it is the restriction of the pushforward to the tangent space at the identity of the group. To spell it out, we take the pushforward of \\rho: G \\times V \\to V, namely d\\rho: T_g G \\times T_v V \\to T_{\\rho(g, v)} V and restrict it to the subspace T_g G \\supset T_e G \\cong \\mathfrak g. So the codomain becomes T_{\\rho(e,v)}V = T_{v} V.\nIf we had a connection on P, then \\omega(X^{A}) = A so we can rewrite the above as\nd\\phi(X^{A}_p ) + \\omega(X^{A}_p)\\bullet_{d\\rho} \\phi(p) = 0\nNow using the above, we can show that D\\phi := d\\phi \\circ \\text{hor} is equals to\nD\\phi(X_p) = d\\phi(X_p) + \\omega(X_p) \\bullet_{d\\rho} \\phi(p)\nby decomposing X=H+V and showing that the above holds for H,V separately.\nPulling back D\\phi(X) to \\nabla_{\\pi_* X}\\sigma\nWe have a good expression for D\\phi : TP \\rightarrow \\Gamma(P_V) (sections of the P_V associated bundle), or pointwise a V-valued one-form D\\phi_p: T_p P \\rightarrow V. Suppose we have a local section \\varphi : \\mathcal U \\rightarrow P, then we can pullback the D\\phi one-form to a one-form on the base manifold \\mathcal U \\subset M. For a vector T\\in  T_x \\mathcal U\n\\begin{aligned}\n\\underbrace{(\\varphi^{*} D\\phi) (T)}_{:=} &amp;= (\\varphi^{*} d\\phi) T + (\\varphi^{*}\\omega)(T) \\bullet_{d\\rho} (\\varphi^* \\phi) (x)\\\\\n\\nabla_T (\\phi \\circ \\varphi) &amp;= d(\\phi \\circ \\varphi) T + \\Gamma(T) \\bullet_{d\\rho} \\phi(\\varphi (x))\\\\\n\\nabla_T s&amp;= ds (T) + \\Gamma(T) \\bullet_{d\\rho} s(x)\n\\end{aligned}\nwhere we \\phi \\circ \\varphi \\equiv s : \\mathcal U \\rightarrow V. The last line is just the usual definition we see for covariant derivative!\nOne can check that all the properties below hold true given the above definition.\nFor f \\in C^{\\infty} (M),\\ T,S \\in T M\n\n\\nabla_{fT+S} \\sigma = f \\nabla_T \\sigma+ \\nabla_S \\sigma\n\\nabla_T \\sigma_1 + \\sigma_2 = \\nabla_T \\sigma_1 + \\nabla_T \\sigma_2\n\\nabla_T (f \\sigma) = T(f) \\sigma + f \\nabla_T \\sigma \n\nExamples\nGeneral Relativity\nIn General Relativity, the principal bundle is the frame bundle LM, with gauge group GL(d). The associated bundle is the tangent bundle TM. Since GL(d) is a matrix group, the action \\bullet_{d\\rho} is just matrix multiplication. The section s:\\mathcal U \\rightarrow TM is a vector field. If there is a coordinate chart x:\\mathcal U \\rightarrow \\mathbb R ^ d, then the section can be decomposed as s^j (x) \\partial_j where s^j :\\mathcal U \\rightarrow \\mathbb R are functions on \\mathcal U.\n\\nabla_T s= ds (T) + \\Gamma(T) \\bullet_{d\\rho} s(x)\nbecomes\n\\begin{aligned}\n(\\nabla_{\\partial_\\mu} s)^i &amp; = [ds(\\partial_\\mu)]^i + {\\Gamma^i}_{j\\mu} s^j \\\\ \n&amp; = \\partial_\\mu (s^i) + {\\Gamma^i}_{j\\mu} s^j\n\\end{aligned}\nTo unpack what we just wrote above, note that \\mathbf \\Gamma_\\mu is a matrix. If we represent \\mathbf s = s^j \\partial_j as a column vector with entries s^j, then the action of \\mathbf \\Gamma_\\mu on \\mathbf s is just matrix multiplication (\\mathbf \\Gamma_\\mu \\mathbf s)^i = {\\Gamma^i}_{j\\mu} s^j\nWe have used property (1) to decompose \\nabla_T into\n\\nabla_{T^\\mu \\partial_\\mu} = T^\\mu \\nabla_{\\partial_\\mu} \nOn the LHS,  \\nabla_{\\partial_\\mu} \\mathbf s is a vector in T_xM so we can extract components (\\nabla_{\\partial_\\mu} \\mathbf s)^i. Do note that this is NOT the same as \\nabla_{\\partial_\\mu} (\\mathbf s^i). The latter is interpreting s^i as functions, and the associated bundle would be the line bundle \\mathbb R. In our case we are dealing with an associated vector bundle, and elements living in the fiber are \\mathbf s(x) \\in T_x M.\nThe \\partial_\\mu(s^i) term is admittedly very ambiguous (my fault). We start from the definition of the pushforward\nds(\\partial_\\mu) := \\partial_\\mu (\\_ \\circ s)\nThe function on \\mathcal U, \\_ \\circ s: \\mathcal U \\to \\mathbb R, is eaten by \\partial_\\mu \\in T_x \\mathcal U to yield a real number. But this ds(\\partial_\\mu) has a blank slot \\_, and is waiting for a function on TM.\nThe ds(\\partial_\\mu) eats a function on TM and outputs a real number. In other words, it is a vector on TM (meaning it lives in TTM, yea!). \\nabla_{\\partial_\\mu} s on the LHS is a vector on TM too. All that remains to settle are the components: to show that\n[ds(\\partial_\\mu)]^i = [\\partial_\\mu(\\_ \\circ s)]^i \\stackrel{!}{=} \\partial_\\mu (s^i)\nActually this doesn’t make sense, because i goes from 1 to d on the RHS, whereas the dimension of the ds(\\partial_\\mu) vector is 2d. The resolution to this is to note that ds(\\partial_\\mu) is a horizontal vector since d(\\pi \\circ s) = \\text{id}_{TM}, so it has effective dimension d. Since d is a linear functional, (ds)^i = d(s^i). Then d(s^i) \\partial_\\mu is just \\partial_\\mu(s^i) by definition. QED\nI’m sorry to leave you on the edge but I do not know how to make the above argument more rigorous. It matches with the GR definition of covariant derivative so I’m sure there is some valid explanation. I think it has to do with the isomorphism T_v V \\cong V but I can’t make this precise. Might update the blog next time (TODO).\nScalar Electrodynamics\nWe switch to the convention that the \\exp map from Lie algebra to Lie group has a factor of i, so \\exp(i \\mathfrak g) = G. This is so that the Lie algebra is real to match physics convention.\nThe section s:M \\to \\mathbb C is the complex line bundle. The action \\rho:G \\to GL(\\mathbb C) is given by complex rotation \\exp{(i \\lambda)} \\bullet_\\rho \\phi = \\exp{(i\\lambda)} \\phi. The pushforward of that action is \\bullet_{d\\rho}: \\mathfrak u(1) \\rightarrow GL(\\mathbb C), given by complex multiplication {\\lambda} \\bullet_{d\\rho} \\phi = i \\lambda \\phi. \\Gamma is the electromagnetic 4-potential A = A_\\mu dx^\\mu, with A_\\mu \\in \\mathbb R \\cong \\mathfrak g.\n\\nabla_T s= ds (T) + \\Gamma(T) \\bullet_{d\\rho} s(x)\nbecomes\n\\begin{aligned}\nD_{\\partial_\\mu}\\phi &amp; = d\\phi(\\partial_\\mu) + A_\\mu \\bullet_{d\\rho} \\phi\\\\\n&amp; = \\partial_\\mu \\phi + i A_\\mu \\phi\\\\\n\\end{aligned}\nIf we had chosen the action to be \\exp(i \\lambda) \\bullet_\\rho \\phi = \\exp(-i\\lambda) \\phi then we would have arrived at - i A_\\mu \\phi instead of + (a more common convention). It is just a matter of convention / choice of action.\nThe Dirac Electrodynamics version is not too different since U(1) just acts on individual components (scalar multiplication as opposed to matrix multiplication) of the Dirac spinor.\nGauge Transformations\nYou hear this in GR: “the covariant derivative transforms like a tensor”. You also see things like D_\\mu&#039; U(x) = U(x) D_\\mu in electrodynamics. It turns out this is unified under the following\n\\begin{aligned}\n\\nabla&#039; \\Omega^{-1} s &amp;= d(\\Omega^{-1} s) + (\\Omega^{-1} \\Gamma \\Omega + \\Omega^{-1} d \\Omega) \\Omega^{-1} s \\\\\n&amp; = d\\Omega^{-1} s + \\Omega^{-1} ds + \\Omega^{-1}\\Gamma s + \\Omega^{-1} d \\Omega \\Omega^{-1} s \\\\\n&amp; = d\\Omega^{-1} s + \\Omega^{-1} ds + \\Omega^{-1}\\Gamma s - d\\Omega^{-1} s \\\\\n&amp; = \\Omega^{-1} (ds + \\Gamma s) \\\\\n&amp; = \\Omega^{-1} \\nabla s\n\\end{aligned}\nwhere we used d\\Omega^{-1} \\Omega + \\Omega^{-1} d \\Omega  = d(\\Omega^{-1} \\Omega) = 0.\nI find it slightly odd that s transforms under \\Omega^{-1} (from the left). I could have made a mistake, or maybe it’s just interpreted as a right action (left vs right differs under composition of actions)."},"old-blogs-(jekyll)/2023-05-02-cech":{"title":"Čech Cohomology for Physicists","links":[],"tags":[],"content":"Our motivation comes from wanting to put Spinors on Curved Spacetime (an upcoming blog)\nTheorem: A spin structure on an orientable Riemannian manifold exists iff the second Stiefel-Whitney class \\check H^2 (M, \\mathbb Z_2)  vanishes.\nLet’s unpack this theorem.\nThe Stiefel-Whitney class is the Čech cohomology class \\check H(M, G) with abelian group G=\\mathbb Z_2.\nMotivation\nHere is an extremely brief intuition for Čech cohomology.\nSuppose we want to define a function on [0,1]. Since this space can be covered by one chart, we can just define f:[0,1] \\rightarrow \\mathbb R.\nHowever, suppose the domain of the function we want to define cannot be covered by one chart alone. For example it is S^1, which can only be covered by at least 3 charts. (Not 2 because we want a good covering meaning that intersections are contractible.)\nAnyway, let’s start simple and say that [0,1] is covered by U=[0,0.6] and V=[0.4, 1]. If we have 2 functions f_U:U\\to\\mathbb R and f_V:V\\to\\mathbb R, then our life would be really easy if the functions agreed pointwise on the intersection U\\cap V\nf_U\\vert_{U\\cap V} = f_V\\vert_{U \\cap V}\nIn which case we can just define f: U \\cup V \\to \\mathbb R by f(U\\backslash U \\cap V) = f_U and f(V\\backslash U\\cap V) = f_V and pick either f_U or f_V on the intersection.\nBut sometimes life isn’t that easy and they disagree on their intersection. Well not all is lost. In the definition of manifolds, the coordinate atlas have transition maps \\phi_i \\circ \\phi_j^{-1}: \\mathbb R^d \\to \\mathbb R^d between different coordinate charts. In the definition of sections (not global sections) of vector bundles, \\sigma_j(m) = \\sigma_i(m) \\bullet_R t_{ij}(m) where t_{ij}(m) \\in G is the transition map acting on vector fibers (source). We can still do calculations as long as there is a specified way to move calculations from one chart to another.\nIn our case of real-valued functions, the transition is just\n(\\delta f)_{U \\cap V} := f_V\\vert_{U\\cap V} - f_U\\vert_{U \\cap V}\nThe Čech differential is a symbol that we use to “generate” transition functions. This is a very specific case of the Čech differential \\delta.\nBreaking Down Definitions\nThe Čech Differential on Wikipedia seems a lot more than what we have just defined. And it is! But let’s try to break down the wiki definition.\nCochain\nMath: The cochain complex C^\\bullet(\\mathcal U, \\mathcal F) is a sequence of q-cochain C^q(\\mathcal U, \\mathcal F) with a coboundary operator \\delta_q:C^q(\\mathcal U, \\mathcal F) \\to C^{q+1}(\\mathcal U, \\mathcal F).\nEnglish: There is a sequence of abelian groups (explained soon) with a linear operator going down the sequence in one direction. An example would be the\n(\\delta f)_{U \\cap V} := f_V\\vert_{U\\cap V} - f_U\\vert_{U \\cap V}\nwe just defined. Linearity would entail that \\delta (f+_q g) = \\delta(f) +_{(q+1)} \\delta(g) where the addition +_k is the addition in abelian group C^k(\\mathcal U, \\mathcal F).\nPresheaf and Restriction Morphism\nMath: \\mathcal F is the presheaf of abelian groups on topological space X. For each inclusion of open sets V \\subset U of X, there is a restriction morphism \\text{res}_{V,U}: F(U) \\to F(V) where F(U) is the set of sections of F over U.\nEnglish: X has a topology which means it has a collection \\mathcal O_X of open sets U_\\alpha that are closed under finite intersection. It is NOT enough that we assign a function f:U \\to \\mathbb R on every U \\in \\mathcal O_X because we mathematicians like to make things as abstract as possible. Instead, we first say that every open set U \\in \\mathcal O_X has a possibly different codomain F(U). This is akin to saying that f_1:(0,1) \\to \\mathbb Z =: F((0,1)) and f_2:(0,0.5) \\to \\mathbb Z_2 =: F((0,0.5)) for a space X=\\mathbb R with the standard topology. This raises concern because now we can’t naively restrict f_1 to a smaller domain (0,0.5) by defining f_1 \\vert_{(0,0.5)} pointwise \\mathbb Z \\not \\subset\\mathbb Z_2. This is why we need a restriction morphism \\text{res}_{(0,1), (0,0.5)}: \\mathbb Z \\to \\mathbb Z_2.\nThis seems like alot of data to provide, and it is: that is the cost of generality. In our case of the spin structure, all codomains are just \\mathbb Z_2 so we won’t need to worry about the restriction morphisms (which are just identity on Z_2). And indeed in our \\delta f example, we mean the trivial restriction with values in F(U) = \\mathbb R.\nAn interesting example of a restriction morphism is in twisted Čech cohomology. In this example twisted cohomology over S^1 roughly corresponds to the Mobius strip.\nDifferential\nMath:\n\\partial_j \\sigma&amp;:=\\left(U_i\\right)_{i \\in\\{0, \\ldots, q\\} \\backslash\\{j\\}}\\\\\n\\partial \\sigma&amp;:=\\sum_{j=0}^q(-1)^{j+1} \\partial_j \\sigma\\\\\n\\left(\\delta_q f\\right)(\\sigma)&amp;:=\\sum_{j=0}^{q+1}(-1)^j \\operatorname{res}_{\\vert\\sigma\\vert}^{\\left\\vert\\partial_j \\sigma\\right\\vert} f\\left(\\partial_j \\sigma\\right)\n\\end{aligned}$$\n\n**English**: \n$\\sigma$ is a collection of open sets (NOT the intersection YET). $\\vert\\sigma\\vert$ is the intersection of this collection. $\\partial_j \\sigma$ drops the $U_j$ from the collection. So $\\partial_j \\sigma$ is a (smaller) subcollection of $\\sigma$. \n\n\nThe intersection of the collection $$\\vert\\partial_j \\sigma\\vert$$ is hence a larger open set than $$\\vert\\sigma\\vert$$ because we have &quot;dropped&quot; one open set $U_j$ in the intersection. Hence restriction morphism goes from the set of functions on $$\\vert\\partial_j \\sigma\\vert$$ to the set of functions on $$\\vert\\sigma\\vert$$.\n\n\nIn the definition above, what is the addition? It occurs in the set of sections/functions (I use them interchangeably) on an open set. Clearly, if we have a 2 functions on $U\\cap V$, we can just add them pointwise. \n\nThis also means that a function on $f: U \\to F(U)$ and $g:V \\to F(V)$, then after applying the restriction morphism on them $$\\text{res}_{U, U \\cap V} : F(U) \\to F(U \\cap V)$$ and $\\text{res}_{V, U\\cap V} : F(V) \\to F(U \\cap V)$, we can add \n\n$$[\\text{res}_{U, U \\cap V}  \\circ f] + [\\text{res}_{V, U\\cap V} \\circ g]$$\n\n\n### Simplex / Simplices\n**Math**: Let $\\mathcal U$ be an open cover of $X$. A $q$-simplex is an ordered collection of $q+1$ open sets from $\\mathcal U$ with non-empty intersection.\n\n**English**: Suppose $U,V,W$ is an open cover of the topological space of interest. 1-simplices would be $U\\cap V$, $U\\cap W$, $V \\cap W$. 2-simplices would be $U \\cap V \\cap W$.\n\n### Cochain\n**Math**: A $q$-cochain of $\\mathcal U$ with coefficients in $\\mathcal F$ is a map which associates each $q$-simplex $\\sigma$ an element of $\\mathcal F(\\vert\\sigma\\vert)$, and we denote the set of all $q$-cochains with coefficients in $\\mathcal F$ by $C^q(\\mathcal U, \\mathcal F)$. $C^q(\\mathcal U, \\mathcal F)$ is an abelian group by pointwise addition.\n\n**English**: Above we wrote $f,g$ as separate functions on open sets $U,V$ respectively. We can pack them together into a 0-cochain $\\omega$ in $C^0(\\mathcal U, \\mathcal F)$ by a linear combination. Personally I like to think of 0-cochains as symbolic linear combination of functions that are defined on any 0-simplex $U, V$. So a 0-cochain might be $f+g$ while another is $2f - 4g$. \n\n### Cocycle\n**Math**: A $q$-cochain is called a $q$-cocycle if it is the kernel of $\\delta_{q}$. We denote this a $Z^q(\\mathcal U, \\mathcal F) := \\ker (\\delta_q) \\subseteq C^q (\\mathcal U, \\mathcal F)$.\n\n**English**: A good example would be the $f,g$ which we packaged into a 0-cochain $\\omega = f+g$ above. Applying the differential on the 0-cochain gives us \n\n$$\\begin{aligned}\n(\\delta_0 \\omega)(U \\cap V) = g\\vert_{U \\cap V}(U \\cap V) - f\\vert_{U \\cap V}(U \\cap V)\n\\end{aligned}$$\n\nIf $\\omega \\in \\ker \\delta_0$, then that would imply $f = g$ agree on the intersection. So $\\omega$ is a &quot;global&quot; section.\n\nIf we had another 0-cochain $2f - 4g$ instead, then\n\n$$\\begin{aligned}\n(\\delta_0 (2f - 4g))(U \\cap V) = 4g\\vert_{U \\cap V}(U \\cap V) - 2f\\vert_{U \\cap V}(U \\cap V)\n\\end{aligned}$$\n\n\nAnother example that hits close to home is appears in (abelian) gauge theory. The transition functions between local trivializations of a principal bundle need to obey the cocycle condition to be well defined\n\n$$g_{ab} g_{bc} = g_{ac}$$\n\nWe can package all the transition functions on the intersections of 2 open sets into a single 1-cochain $g$, a collection of functions $g_{ij}$ on 1-simplicies, which are intersections of 2 open sets $U_i \\cap U_j$. The gauge cocycle condition can be rephrased as the statement that the 1-cochain $g$  is a 1-cocycle\n\n$$0 = (\\delta_1g)(U_a \\cap U_b \\cap U_c) = g_{bc} - g_{ac} + g_{ab}$$\n\nwhere we have written it additively for an abelian gauge group. \n\n### Cohomology\nThe Čech differential squares to $0$, the identity element in the abelian group. i.e. $\\delta_{q+1} \\circ \\delta_q = 0$ \n\nAny time an operator squares to $0$, homology can be defined. Of course whether the homology is actually nontrivial is something else one needs to investigate.\n\n# Example 1: $\\check  H^*(D_1, \\mathbb{R})$\n\nThis example builds intuition for the differential.\n\nLet&#039;s work with abelian group $\\mathbb R$ and trivial restriction morphisms. We consider the topological space to be open disk $D_1$.\n\nSuppose we have 3 charts $U,V,W$ covering $D_1$ (Venn diagram style). Suppose we have a 0-cochain $f$ (a generalized notion of function on $D_1$) consisting of  $f_U: U\\to \\mathbb R$, $f_V: V \\to \\mathbb R$, $f_W: W \\to \\mathbb R$. These 3 functions are **different** functions, NOT a single global function restricted to the 3 charts.\n\nThere are transition functions between $U,V$, i.e. \n\n$$(\\delta_0 f) (U \\cap V) = f_V (U \\cap V) - f_U (U \\cap V) =: f_{VU}$$\n\nand likewise for $f_{UW}, f_{VW}$. These 3 transition functions could clearly be nonzero (nobody said $f$ is a 0-cocycle). We can package these 3 transition functions up into a 1-cochain. Then one observes that this 1-cochain is a 1-cocycle.\n\n$$\\begin{aligned}\n(\\delta_1 (\\delta_0 f))(U \\cap V \\cap W) &amp;= f_{VW} - f_{UW} + f_{UV} \\\\\n&amp;= (f_V - f_W) - (f_U - f_W) + (f_U - f_V) \\\\\n&amp; = 0\n\\end{aligned}$$\n\nwhere the evaluation on $U \\cap V \\cap W$ is suppressed on the RHS.\n\nHowever, the cochain is a very huge space if we choose the abelian group to be the set of real numbers. There are many many functions. So in the next example, we will restrict to constant functions.\n\n# Example 2: $\\check  H^*(D_1, \\underline{\\mathbb R})$\nThis example will recover de Rham cohomology.\n\nWe work with abelian group $\\underline{\\mathbb R}$ of constant functions and trivial restriction morphisms. Considering the space $X=D_1$, the 0-cochain is specified by 3 real numbers $f_U, f_V, f_W$ so $C^0 (\\mathcal U, \\underline {\\mathbb R}) \\cong \\mathbb R^3$. Likewise, $C^1 (\\mathcal U, \\underline {\\mathbb R}) \\cong \\mathbb R^3$ is spanned by $f_{UV}, f_{UW}, f_{VW}$. \n\n\n## Showing $\\check  H^0(D_1, \\underline{\\mathbb R}) \\cong \\mathbb R$\nIf we represent $\\delta_0$ as a matrix we have \n\n\\begin{aligned}\n(\\delta_0){ij} &amp; = \\left(\\begin{array}{ccc}\n1 &amp; -1 &amp; 0 \\\n1 &amp; 0 &amp; -1 \\\n0 &amp; 1 &amp; -1\n\\end{array}\\right){ij}\\\n\\left(\\begin{array}{c}\n(\\delta_0 f){UV} \\\n(\\delta_0 f){UW} \\\n(\\delta_0 f)_{VW}\n\\end{array}\\right) &amp; = \\left(\\begin{array}{ccc}\n1 &amp; -1 &amp; 0 \\\n1 &amp; 0 &amp; -1 \\\n0 &amp; 1 &amp; -1\n\\end{array}\\right)\\left(\\begin{array}{c}\nf_U \\\nf_V \\\nf_W\n\\end{array}\\right)\n\\end{aligned}\n\nThe null space $\\ker \\delta_0 \\cong \\text{span}(f_U + f_V + f_W)$ is 1-dimensional. So $Z^0(\\mathcal U, \\underline{\\mathbb R}) \\cong \\mathbb R$. \n\nThe $B^0(\\mathcal U, \\underline{\\mathbb R}) \\cong \\text{im } \\delta_{-1}$ doesn&#039;t exist, so $ \\check H^0(\\mathcal U, \\underline{\\mathbb R}) \\cong Z^0(\\mathcal U, \\underline{\\mathbb R}) \\cong \\mathbb R$. \n\n\n## Showing $\\check H^1(D_1, \\underline{\\mathbb R}) \\cong \\mathbb 0$\n\nTo find $\\check H^1 \\cong Z^1 / B^1$, we need to calculate $\\ker \\delta_1$ and $\\text{im } \\delta_0$. By rank nullity theorem, \n\n\\begin{aligned}\n\\dim \\text{im } \\delta_0 &amp; = \\dim C^0 - \\dim \\ker \\delta_0  \\\n&amp; = 3 - 1 \\\n&amp; = 2\n\\end{aligned}\n\nNow to calculate $\\ker \\delta_1$ we again to the matrix form\n\n\\begin{aligned}\n(\\delta_1){ij} &amp; = \\left(\\begin{array}{ccc}\n1 &amp; -1 &amp; 1\n\\end{array}\\right){ij}\\\n\\left(\\begin{array}{c}\n(\\delta_1 f){UVW}\n\\end{array}\\right) &amp; = \\left(\\begin{array}{ccc}\n1 &amp; -1 &amp; 1\n\\end{array}\\right)\\left(\\begin{array}{c}\nf{UV} \\\nf_{UW} \\\nf_{VW}\n\\end{array}\\right)\n\\end{aligned}\n\nThe null space of this linear transformation is spanned by 2 vectors $\\ker \\delta_1 \\cong \\text{span}\\{(1,1,0), (-1,0,1)\\}$. So $\\dim \\ker \\delta_1 = 2$. \n\nSo $\\check H^1(\\mathcal U, \\underline{\\mathbb R}) \\cong 0$. There is a nuance I glossed over in which technically speaking cohomology of the topological space $\\check H^1(D_1) = \\lim_{\\rightarrow \\mathcal U} (\\check H(\\mathcal U))$ is the direct limit of the open covers $\\mathcal U$ (see [details](en.wikipedia.org/wiki/%C4%8Cech_cohomology#Cohomology)). We did not prove that our choice of covering is in fact the limit.\n\n## Showing $\\check H^2(D_1, \\underline{\\mathbb R}) \\cong \\mathbb 0$\n\nSince $\\delta_2: C^2(D_1,  \\underline{\\mathbb R}) \\to 0$, the kernel $\\ker \\delta_2 \\cong C^2$ is just the entire space, which has dimension 1 spanned by $f_{UVW}$. \n\nThen first isomorphism theorem (rank nullity if talking about dimension) tells us that $\\text{im } \\delta_1 \\cong \\mathbb R$ since $\\ker \\delta_1 \\cong \\mathbb R^2$ and $C^1 \\cong \\mathbb R^3$. \n\nHence $\\check H^2(D_1, \\underline{\\mathbb R}) \\cong \\mathbb \\ker \\delta_2 / \\text{im }\\delta_1 \\cong \\mathbb R / \\mathbb R \\cong 0$.\n\n## Agreement with de Rham cohomology\nA [theorem](en.wikipedia.org/wiki/De_Rham_cohomology#Sheaf-theoretic_de_Rham_isomorphism) says that de Rham cohomology agrees with constant sheaf Čech cohomology $$H^*_{dR}(M) \\cong \\check H^* (M, \\underline{\\mathbb R})$$.\n\n# Example 3: $\\check H^*(S^1, \\underline{\\mathbb R})$\n\nLet&#039;s calculate de Rham cohomology of $S^1$. The only difference between $S^1$ and the $D_1$ derived above is that $C^2(D_1,\\underline{\\mathbb R}) \\cong \\mathbb R$ is spanned by $f_{UVW}$ but $C^2(S^1, \\underline{\\mathbb R}) \\cong \\mathbb 0$ because the intersection $U\\cap V \\cap W = 0$ vanishes on $S^1$. This means we only need to recalculate $\\check  H^1(S^1, \\underline{\\mathbb R})$.\n\n## Showing $\\check H^1(S^1, \\underline{\\mathbb R}) \\cong \\mathbb R$\nSince $B^1 = \\text{im } \\delta_0$ remains 2 dimensional, we just need to recalculate $Z^1 = \\ker \\delta_1$. However, $\\delta_1 : \\mathbb C^1 \\to 0$, so the kernel is just the entire $C^1 \\cong \\mathbb R^3$. Hence $\\check H^1 \\cong Z^1 / B^1 \\cong \\mathbb R$.\n\n## $\\check H^0, \\check H^2$ are the same as that of $D_1$\nThe rest stay the same i.e. $\\check H^0(S^1, \\underline{\\mathbb R}) \\cong \\mathbb R$ and $\\check H^2(S^1, \\underline{\\mathbb R}) \\cong 0$\n\n\n## Agreement with de Rham\nIt coincides with $$H^0_{dR}(S^1) \\cong \\mathbb R$$ and $$H^1_{dR}(S^1) \\cong \\mathbb R$$ and $$H^2_{dR}(S^1) \\cong \\mathbb 0$$ ([source](en.wikipedia.org/wiki/De_Rham_cohomology#The_n-sphere)).\n\n# Example 4: $$\\check H^*(S^1, \\mathbb Z_2)$$\n\nIn our effort to build towards orientability of manifolds, we will run through a simple calculation of $S^1$ first.\n\nThe calculations with $$\\check H^*(S^1, \\mathbb Z_2)$$ are virtually identical to that of $\\check H^*(S^1, \\underline{\\mathbb R})$, just that the kernel $\\ker \\delta_0$ looks like vectors of the form $f_U = f_V = f_W\\ (\\text{mod } 2)$ instead of equality. This means that the vector space $Z^0 = \\ker \\delta_0 \\cong \\mathbb Z_2$, instead of $\\mathbb R$. \n\nAfter minimal effort we get $\\check H^0(S^1, \\mathbb Z_2) \\cong \\check H^1(S^1, \\mathbb Z_2) \\cong \\mathbb Z_2$. It will turn out that $\\check H^1(S^1, \\mathbb Z_2)$ is related to orientability and the fact that there are 2 line bundles over $S^1$: the trivial line bundle (cylinder) and the Mobius strip.\n\nWe also see that $\\check H^2(S^1, \\mathbb Z_2) \\cong 0$, and this will turn out to be related to the statement that you can put a spin structure on $S^1$.\n\n# Stiefel Whitney Class\n\n## Explanation\n\nA small digression on what it is.\n\n**Math**: For a real vector bundle $E \\to X$, the [Stiefel-Whitney class](en.wikipedia.org/wiki/Stiefel%E2%80%93Whitney_class) of $E$ is denoted by $w(E)$. It is an element of the cohomology ring\n \n$$H^{\\ast }(X;\\mathbb {Z} /2\\mathbb {Z} )=\\bigoplus _{i\\geq 0}H^{i}(X;\\mathbb {Z} /2\\mathbb {Z} )$$\n \nso an element of the class is the a sum \n\n$$w(E)=w_0(E)+w_1(E)+w_2(E)+\\cdots$$\n\nwhere each $w_i(E) \\in H^i (X; \\mathbb Z/2\\mathbb Z)$.\n\n**English**: Remember that the sum we see in $w(E)$ is a formal sum, meaning that $w_0(E)$ and $w_1(E)$ don&#039;t live in the same vector space but rather in the direct sum $H_0 \\oplus H_1$. So it is more like a &quot;tuple&quot; of elements than a sum. \n\nThe cohomology ring ([video](youtu.be/kTf-YE6WWaM)) $H^{\\ast }(X;\\mathbb {Z} /2\\mathbb {Z} )$ is basically just this direct sum $\\oplus$ of the sequence of cohomology groups $H^{i}(X;\\mathbb {Z} /2\\mathbb {Z} )$. The sum has some additional structure like [cup product](en.wikipedia.org/wiki/Cup_product) that gives this ring a [grading](en.wikipedia.org/wiki/Graded_ring), but that isn&#039;t our immediate concern now. \n\nEach cohomology group ([video](youtu.be/ZTgnSPYRCDk)) $H^i(X; \\mathbb Z / 2 \\mathbb Z)$ is a set of $\\mathbb Z_2$-valued &quot;functions&quot; on $X$ (satisfying some conditions, cocycle but not coexact to be precise). The &quot;functions&quot; is in quotes because strictly speaking it is the (dual) group of homomorphisms $C^*_i := \\text{Hom}(C_i, A)$ where $C_i$ is the singular chain complex. Read more about it in [cohomology](en.wikipedia.org/wiki/Cohomology).\n\n### Pedantic Note\nthat the Stiefel-Whitney class is calculated on the **vector bundle**, but it produces values in the cohomology ring of the **base manifold**. This means that when people say &quot;first Stiefel-Whitney class vanishes&quot; they mean that the class&#039; **value** in the cohomology ring is $0$. Nobody needs the **cohomology ring** itself to be the $0$ vector space. Analogy: we mean to say the vector is the zero vector, not that the entire vector space has dimension 0. Vanishing characteristic class is a property of the vector bundle, NOT the manifold. When people say the characteristic class vanishes for the manifold, they usually mean the **tangent bundle** of the manifold.\n\n### Example\nFirst Stiefel-Whitney class of the [Möbius strip](en.wikipedia.org/wiki/Fiber_bundle#M%C3%B6bius_strip) has just one element other than 0, while that of the trivial line bundle over $S^1$ is $0$. So the Möbius strip is a nontrivial line bundle over $S^1$. \n\n## Significance in Physics\nFirst Stiefel-Whitney class tells us whether a manifold is orientable.\n\nSecond Stiefel-Whitney class tells us whether a manifold has a spin structure.\n\nBoth are required to vanish to put spinors on a manifold, which is what we need if we were to describe fermions in curved spacetime.\n\n## First Stiefel Whitney Class $w_1(TM) \\in \\check H^1(M, \\mathbb Z_2)$\nThese [paper](arxiv.org/abs/1911.09766), [notes](math.colorado.edu/~rohi1040/expository/param_spin.pdf), [best notes](webspace.science.uu.nl/~caval101/homepage/Differential_geometry_2014_files/notes%20on%20Cech%20cohomology.pdf) are good resources on this. \n\nThere are multiple equivalent definitions of orientability of a manifold, we mention the following two.\n\n[Definition 1.4 of ncatlab](ncatlab.org/nlab/show/orientation): An orientation of $M$ is an orientation of the tangent bundle $TM$.\n\n[Definition using $GL^+(n)$](en.wikipedia.org/wiki/Orientability#Orientability_of_differentiable_manifolds): If the tangent bundle $TM$ has a structure group $GL(n, \\mathbb R)$ that can be [reduced](en.wikipedia.org/wiki/G-structure_on_a_manifold#Reduction_of_the_structure_group) to $GL^+(n, \\mathbb R)$ of positive determinant matrices, then the manifold is said to be orientable.\n\n[Theorem](en.wikipedia.org/wiki/Orientability#Orientation_and_cohomology): A manifold is orientable iff the first Stiefel Whitney class $w_1(TM) \\in H^1(M; \\mathbb Z_2)$ of the tangent bundle $TM$ vanishes.\n\nA proof can be found in Corollary 2.16 of [this](webspace.science.uu.nl/~caval101/homepage/Differential_geometry_2014_files/notes%20on%20Cech%20cohomology.pdf) with $E=TM$\n\n### Intuition\nFor better intuition about this, one can actually prove that a trivial cohomology $H^1(M; \\mathbb Z_2) \\cong 0$ (which is more stringent than $w_1(TM) = 0$) would imply that the manifold has a $GL^+$-structure, using Cech cohomology as follows: \n\nA differentiable manifold naturally allows for the definition of a principal $GL(n;\\mathbb R)$-bundle via the tangent frame bundle construction. This means there exists transition maps $t_{ij}: \\mathcal U_i \\cap \\mathcal U_j \\to GL(n; \\mathbb R)$. One can also construct the associated bundle $\\mathbb R^n$. Sections $\\sigma_i: \\mathcal U_i \\to \\mathbb R^n$ of this associated bundle are acted on from the right by transition maps over overlapping charts $\\sigma_j = \\sigma_i \\bullet_R t_{ij}$ (see my [blog](tch1001.github.io/math/physics/qft/gauge%20theory/2023/04/27/ehresmann.html) for details). From the existing sections $\\sigma$ and transition maps $t$, we would like to construct a new pair of sections $\\tilde \\sigma$ and $\\tilde t$ such that $\\tilde t \\in GL^+(n; \\mathbb R)$. We first construct $\\mathbb Z_2$-valued transition functions $c_{ij} := \\text{sign}(\\det t_{ij}) \\in \\mathbb Z_2$. This collection of $c_{ij}$ functions define a Cech 1-cochain $c$. The principal $GL$-bundle cocycle condition $t_{ij} t_{jk} t_{ki} = 1$ translates to the fact that $c$ is a 1-cocycle. Since $H^1(M;\\mathbb Z_2) \\cong 0$, all cocycles are coexact, which implies that there exists a 0-cochain $\\phi$ such that $$c_{ij} = (\\delta \\phi)_{ij} = \\phi_j \\phi_i^{-1}$$. In other words, there is an assignment of $+,-$ to each chart such that the transition functions are given by the change in signs when moving between overlapping charts. What remains to do is &quot;flip&quot; all the $-$ charts so that the transition functions are all positive. To do this formally, we define the new sections to be $\\tilde \\sigma_i := \\phi_i  \\sigma_i$. The new sections would have new transition maps $\\tilde t_{ij}$, which we will show have positive determinant.\n\n$$\\begin{aligned}\n\\sigma_j &amp;= \\sigma_i t_{ij} \\\\\n\\tilde \\sigma_j &amp;= \\tilde \\sigma_i \\tilde t_{ij} \\\\\n\\Rightarrow \\phi_j \\sigma_j &amp;= \\phi_i \\sigma_i \\tilde t_{ij} \\\\\n\\Rightarrow \\sigma_j &amp;= \\sigma_i \\phi_j^{-1} \\phi_i \\tilde t_{ij} \\\\\n\\Rightarrow t_{ij} &amp;= \\phi_j^{-1} \\phi_i \\tilde t_{ij} \\\\\n\\Rightarrow \\tilde t_{ij} &amp;= t_{ij} \\phi_j \\phi_i^{-1} \\\\\n\\Rightarrow \\det \\tilde t_{ij} &amp;= \\det t_{ij} \\text{ sign} (\\det t_{ij})\\\\\n&amp;= \\vert\\det t_{ij}\\vert &gt; 0\n\\end{aligned}$$\n\nHence we have performed reduction of the $GL$-bundle to a $GL^+$-bundle using the fact that $\\check H^1(M; \\mathbb Z_2) \\cong 0$. \n\nAnother useful way to think about this is that trivial first cohomology allows us to reduce $O$-structure to $SO$-structure. This will sit well when we talk about trivial second cohomology allowing us to reduce $SO$-structure to $\\text{Spin}$-structure (yes we still call it a reduction, which is a bad phrasing for this procedure, as said in [wiki](en.wikipedia.org/wiki/G-structure_on_a_manifold#Reduction_of_the_structure_group)).\n\n&lt;!-- We can extract abit more intuition from this. We saw that we required $\\check H^1(M;\\mathbb Z_2) \\cong 0$ in our working, but the theorem only uses $w_1(TM) = 0$, which is a weaker condition. We can interpret use this to form intuition about what Stiefel Whitney classes calculate: All transition functions $t_{ij}\\in GL(n; \\mathbb R)$ between sections in $E$ have determinant sign $c_{ij} := \\text{sign}(\\det t_{ij})$, which define a 1-cocycle that lies in 1st Stiefel Whitney class $[c]\\in w_1(E)$ (this is the *definitive intuition for Stiefel Whitney class*). If $w_1(E) = \\{[0]\\}$, then that would imply that $[c] = [0] \\Rightarrow c = 0+\\delta \\phi$, and the rest of the above working follows. --&gt;\n\n## Second Stiefel Whitney Class $w_2(TM) \\in \\check H^2(M, \\mathbb Z_2)$\n\nThis [notes](web.math.utk.edu/~freire/teaching/m664s22/Spin_Structures.pdf) is good.\n\n[Definition](en.wikipedia.org/wiki/Spin_structure#Spin_structures_on_Riemannian_manifolds): A spin structure on an orientable Riemannian manifold $M$ with an oriented vector bundle $TM$ is an equivariant lift of the orthonormal tangent frame bundle $F_{SO}(TM)\\to M$ with respect to the double covering $\\rho: \\text{Spin}(n) \\to SO(n)$. \n\nThe &quot;equivariant lift&quot; means that the principal $\\text{Spin}$-bundle $$P_{\\text{Spin}}$$ must have its right action of $\\text{Spin}(n)$ on the fibers of $$P_{\\text{Spin}}$$ be consistent with the right action of $SO(n)$ on $P_{SO}$. Let $\\phi: P_\\text{Spin} \\to P_{SO}$ be the 2-fold covering map. Then $\\phi$ being equivariant means that for $p\\in P_\\text{Spin}, q \\in \\text{Spin}(n)$\n\n$$\\phi(p \\bullet_{R,P_\\text{Spin}} q) = \\phi(p) \\bullet_{R,P_{SO}} \\rho(q)$$\n\nAny principal bundle will have transition maps, so the transition maps $\\tilde g_{ij}$ of $P_\\text{Spin}$ must obey \n\n$$\\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki} = \\text{id}_{\\text{Spin}(n)}$$\n\n[Theorem](en.wikipedia.org/wiki/Spin_structure#Obstruction): A spin structure exists if and only if the second Stiefel-Whitney class $w_2(TM) \\in \\check H^2(M; \\mathbb Z_2)$ vanishes.\n\n### Intuition\n\nTo build intuition for what $w_2(TM)$ is, we follow a similar procedure as we did for $w_1(TM)$ and orientability. We will show that if $\\check H^2(M; \\mathbb Z_2) \\cong 0$ vanishes (stricter than $w_2(TM) = 0$), then we can construct this equivariant lift from $SO(n) \\to \\text{Spin}(n)$ of principal bundles.\n\nWe start from the $SO(n)$ bundle, so the transition maps $g_{ij}$ satisfy the cocycle condition $$g_{ij} g_{jk} g_{ki} = \\text{id}_{SO(n)}$$. We want to lift this to $\\tilde g_{ij}$. But we are worried that $$\\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki} = \\text{id}_{\\text{Spin}(n)}$$ fails to hold. Namely, we are only certain that $$\\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki} \\in \\{-1, 1\\}$$ since \n\n$$\\begin{aligned}\n\\rho(\\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki}) \n&amp;= \\rho(\\tilde g_{ij}) \\rho(\\tilde g_{jk}) \\rho(\\tilde g_{ki})\\\\\n&amp;= g_{ij} g_{jk} g_{ki}\\\\\n&amp;= \\text{id}_{SO(n)}\n\\end{aligned}$$\n\nWe aim to construct *new* transition maps $$\\tilde g_{ij}&#039;$$ that satisfy the cocycle condition $$\\tilde g&#039;_{ij} \\tilde g&#039;_{jk} \\tilde g&#039;_{ki} = \\text{id}$$. And we can make use of the cohomology to do this. Observe that for every 3 coordinate patches $\\mathcal U_i \\cap \\mathcal U_j \\cap \\mathcal U_k$ we can define a 2-cochain $w_{ijk} := \\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki}$ with values in $\\mathbb Z_2$. One can check that this 2-cochain is a 2-cocycle.\n\n$$\\begin{aligned}\n(\\delta w)_{ijkl} \n&amp;= w_{jkl} w^{-1}_{ikl} w_{ijl} w^{-1}_{ijk}\\\\\n&amp;=( \\tilde g_{jk} \\tilde g_{kl} \\tilde g_{lj} )\n(\\tilde g_{ik} \\tilde g_{kl} \\tilde g_{li})^{-1}\n(\\tilde g_{ij} \\tilde g_{jl} \\tilde g_{li} )\n(\\tilde g_{ij} \\tilde g_{jk} \\tilde g_{kl})^{-1}\\\\\n&amp;= 1\n\\end{aligned}$$\n\nSince $\\check H^2(M; \\mathbb Z_2) \\cong 0$, this implies that $$w_{ijk} = (\\delta h)_{ijk}$$ for some 1-cochain $h$ spanned by $h_{ij} \\in \\mathbb Z_2$. Expanding both sides of $w = \\delta h$ shows that\n\n$$\\begin{aligned}\nw_{ijk} &amp; = \\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki}\\\\\n(\\delta h)_{ijk} &amp;= h_{ij} h_{jk} h_{ki} \n\\end{aligned}$$\n\nThis relates the $\\text{Spin}$-valued 1-cochain $\\tilde g$ to the $\\mathbb Z_2$-valued 1-cochain $h$. Whatever value $$(\\delta \\tilde g)_{ijk} = \\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki} \\in \\mathbb Z_2$$ is, is the same as $$(\\delta h)_{ijk} = h_{ij} h_{jk} h_{ki} $$. All that is left to do is define new transition maps $$\\tilde g&#039;_{ab} := \\tilde g_{ab} h_{ab}$$, which satisfies the cocycle condition since $\\tilde g_{ij} \\tilde g_{jk} \\tilde g_{ki}  = h_{ij} h_{jk} h_{ki}$ and $x^2 = 1\\ \\forall\\ x \\in \\mathbb Z_2$.\n\nTo summarise, the argument goes like: if the transition maps for $\\text{Spin}(n)$ didn&#039;t satisfy cocycle, we know the cocycle at least is in $\\mathbb Z_2$ since the transition maps for $\\text{SO}(n)$ satisfy cocycle, and kernel of $\\rho : \\text{Spin}(n) \\to SO(n)$ is $\\mathbb Z_2$. Then by trivial cohomology $\\check H^2(M; \\mathbb Z_2)\\cong 0$, we know that all 2-cocycles are coexact, which allow us to construct a 1-cochain valued in $\\mathbb Z_2$ to multiply with the 1-cochain valued in $\\text{Spin}(n)$, and this new 1-cochain $\\tilde g&#039;$ is a 1-cocycle (satisfies the cocycle condition).\n\n## Uniqueness of Spin Structure\n[Lecture](youtu.be/Vsy8dlsr8G0) \n\nThere is a bijection between spin structures on a manifold and $\\check H^1(M;\\mathbb Z_2)$. This drives home the point that $\\check H^1(M;\\mathbb Z_2)$ need *not* be trivial for the manifold to be orientable. A good example would be $S^1$. The Mobius line bundle over $S^1$ is not orientable, while the trivial bundle and the tangent bundle is orientable. $S^1$ has trivial second cohomology $\\check H^2(S_1;\\mathbb Z_2) \\cong 0$ so we can put a spin structure on $S^1$. Is this spin structure unique? No. Because there are 2 elements in $\\check H^1(S^1;\\mathbb Z_2) \\cong \\{[-1], [1]\\}$. So there are 2 distinct spin structures on $S^1$. \n\n&lt;!-- There a few equivalent definitions. We will choose the definition involving tangent bundle. \n\n[Definition](en.wikipedia.org/wiki/Orientability#Orientability_of_differentiable_manifolds): The orthonormal tangent frame bundle $F_O(TM)$ is a principal $O(n, \\mathbb R)$-bundle. There are transition maps $g_{\\alpha\\beta} : \\mathcal U_{\\alpha \\beta} \\to O(n, \\mathbb R)$. The manifold is said to be orientable if there exists a subbundle of $F_O(TM)$ (called the oriented orthonormal tangent frame bundle $F_{SO}(TM)$) with transition maps $g&#039;_{\\alpha\\beta}: \\mathcal U_{\\alpha\\beta} \\to SO(n, \\mathbb R)$. --&gt;\n&lt;!-- Proof of &quot;$\\Rightarrow$&quot;: Suppose $g&#039;_{ij} : \\mathcal U_{ij} \\to SO(n,\\mathbb R)$ are the transition functions between oriented orthonormal frames over $\\mathcal U_i$ and $\\mathcal U_j$. Then we can form a constant $\\mathbb Z_2$-valued function on $\\mathcal U_{ij}$ by \n\n$$c_{ij} := \\det g_{ij} = 1$$\n\nThe collection of $c_{ij}$ forms a Cech 1-cochain (recall that 1-cochains are functions defined on intersections of 2 open sets). One can show that it is a Cech 1-cocycle due to the cocycle condition on the principal bundle transition maps\n\n$$\\begin{aligned}\n(\\delta c)_{ijk} &amp;= c_{jk} c^{-1}_{ik} c_{ij} \\\\\n&amp;= \\det g_{jk} \\underbrace{g^{-1}_{ik}}_{=g_{ki}} g_{ij} \\\\\n&amp;= \\det \\underbrace{g_{jk} g_{ki}}_{\\text{cocycle}} g_{ij} \\\\\n&amp;= \\det g_{ji} g_{ij} \\\\\n&amp;= 1 \n\\end{aligned}$$\n\nSince $H^1$ is the space of cocycles that are NOT coboundaries, to ask whether $c \\in H^1$ is to ask whether it is a coboundary, i.e. $c_{ij} = (\\delta \\phi)_{ij}$ for some 0-cochain $\\phi$. --&gt;\n\n&lt;!-- $$\\begin{aligned}\nc_{ij} c_{jk} c_{ki} &amp; = \\det g_{ij} \\det g_{jk} \\det g_{ki}\\\\\n&amp; = \\det g_{ij} g_{jk} g_{ki} \\\\\n&amp; = \\det (\\text{id}_{SO(n, \\mathbb R)}) \\\\ \n&amp; = 1 \n\\end{aligned}$$ --&gt;\n\n&lt;!-- We can compute first Stiefel Whitney class ${{H}}^1(M, \\mathbb Z_2) \\cong \\check H^1(\\mathcal U, \\mathbb Z_2)$ by choosing an appropriate good cover $\\mathcal U$ of $M$ and computing the Cech cohomology with abelian group $\\mathbb Z_2$.\n --&gt;"},"old-blogs-(jekyll)/2023-06-20-ssl-2":{"title":"Setting Up SSL Manually on Kubernetes Traefik: ACME HTTP Challenge","links":[],"tags":[],"content":"Btw, I will guide you in setting up SSL for any site for $25 (around 1h meeting online), contact me at @tch1001 and save yourself alot of pain in the ass :)\nToday, I will show you how to setup SSL on Kubernetes the manual way. I will be using Traefik as the Ingress Controller and Let’s Encrypt as the Certificate Authority. In the previous article, I talked about how to perform ACME using DNS. But today I had to perform a renewal of cert without access to the DNS (but having access to the web server). So I had to use the HTTP ACME challenge instead.\nRefer to part 1 for server setup\nCertbot SSL Setup\nIf you want to use “DNS only” and still have SSL, or you want “Proxied” with Full encryption mode, you need to create a certificate using Certbot. Certbot is a free, open-source tool for automatically using Let’s Encrypt certificates on manually-configured HTTPS servers.\nUsually, people use certbot because it’s very automatic, but in this case I have chosen to manually obtain my certificates and upload it because I want to learn how it works, and have greater control over the process. I have found that when I try to do it automatically using Traefik, there is a lot of fiddling and restarting the services, possibly resulting in downtime.  Through the manual method, you don’t need to touch the my-service Service, and just need to update the IngressRoutes.\nFirst, you need to install certbot. After that you can run\nsudo certbot certonly --manual --preferred-challenge http -d my3.domain.com\n\n\n--manual is required if we want to use the HTTP acme challenge.\n-d my3.domain.com indicates the domain (leaving it out will prompt you to input it manually).\n\nYou will see something like\nCreate a file containing just this data:\n\n3H7J8MdG5anbZ0bIi3kNarqT1QxESoMdbCGMmemFHDd.ypmiVlOlYgU_sU-90HbZhcPvk6BiHkxyIxWjYRQllEQ\n\nAnd make it available on your web server at this URL:\n\nmy3.domain.com/.well-known/acme-challenge/3H7J8MdG5anbZ0bIi3kNarqT1QxESoMdbCGMmemFHDd\n\nPress Enter to Continue\n\nSo now you need to create a txt file that the ACME certbot can access via your domain to prove that you have control over the domain. This will differ according to the web server you have. But for me it was nodejs so I just put the file in static/.well-known/acme-challenge folder\nAnd then built and pushed the new docker image\ndocker build -t tch1001/newimage:v2\ndocker push tch1001/newimage:v2\nvim kubernetes/servers/webserver.yaml # edit the version\nk apply -f kubernetes/servers/webserver.yaml\n\nAfter that I return to the ACME certbot and press enter. If all goes well, you will see\nSuccessfully received certificate.\nCertificate is saved at: /etc/letsencrypt/live/my3.domain.com/fullchain.pem\nKey is saved at:         /etc/letsencrypt/live/my3.domain.com/privkey.pem\nThis certificate expires on 2023-06-04.\nThese files will be updated when the certificate renews.\n\nSetting HTTP redirection to HTTPS\nThe rest of the blog is a duplicate of part 1"},"old-blogs-(jekyll)/2023-06-22-expander":{"title":"LaTeX Expander","links":["downloads/symch2","downloads/symch"],"tags":[],"content":"I wrote something to help me write LaTeX more easily. I call it symch v2. It stands for Symbolic Chien Hao lol.\nv1 is here."},"old-blogs-(jekyll)/2023-08-13-kernel-notes":{"title":"My Kernel Notes (Old)","links":[],"tags":[],"content":"I had some notes from a while back, here is a dump of them. It is very disorganised and not meant to be pedagogical.\nmy kernel exploration\nRun the following as root\nmake\ninsmod hello-1.ko\ndmesg -w # preferably in another window\nrmmod hello-1.ko\nmake clean\ngit status\n\nfor the char device testing\nmake test\n./cdev_test\nmake clean\n\nFor inverting screen colors\napt install libx11-dev libxxf86vm-dev libxrandr-dev\nmake invert\n\nIf things don’t work, try\nsudo systemctl restart display-manager\nxhost +\n\nWriting assembly\ngcc -S helloworld.c # compiler\nvim helloworld.s # modify stuff\ngcc helloworld.s # assembler and linker\n./a.out\n\nCompile the kernel\nMethod 1 (worked for me)\n# download from kernel.org\napt install -y libncurses5 libncurses5-dev bison flex\nmake menuconfig\nvim .config # remove debian things\napt install -y libssl-dev libelf-dev\nmake -j2\nmake modules_install\nmake install\n\nMethod 2 (didn’t work for me)\napt-get source linux-image-`uname -r`\ncd folder\nfakeroot debian/rules clean\n\nCross compiling the kernel\nGetting binutils and gcc from apt\nDo this if you’re a noob\napt-get install binutils-riscv64-linux-gnu gcc-riscv64-linux-gnu\nriscv64-linux-gnu-ld --version\nriscv64-linux-gnu-gcc --version\n\nBuilding binutils from source\nexport TARGET=aarch64-unknown-linux-gnu     # replace with your intended target\nexport PREFIX=&quot;$HOME/opt/cross/aarch64&quot;     # replace with your intended path\nexport PATH=&quot;$PREFIX/bin:$PATH&quot;\nwget ftp://ftp.gnu.org/gnu/binutils/binutils-2.29.1.tar.xz \ntar -xf binutils-2.29.1.tar.xz\ncd binutils-2.29.1\n./configure \\\n  --target=$TARGET \\\n  --prefix=$PREFIX \\\n  --with-sysroot \\\n  --disable-nls \\\n  --disable-werror\nmake \nmake install\n$TARGET-ld --version\n\nCross compiling the kernel\nmake ARCH=riscv O=kernel_build defconfig\nexport TARGET=aarch64-unknown-linux-gnu-     \nmake ARCH=riscv CROSS_COMPILE=$TARGET modules\n\nContributing to mailing list\ngit clone --depth=1 git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth-next.git/\ncd bluetooth-next\n# compile kernel as per usual\ngit checkout &lt;for-next&gt;\n# obtain patch from email\ngit am update.patch\npatch -p1 &lt; update.patch # do this cos git apply doesnt work (insert 1h of vulgarities)\ngit am --continue\n\nMake our initramfs\nEither use\n$ mkinitramfs -o ramdisk.img # doesn&#039;t work right now\n\nOR make your own\n$ mkdir vfs &amp;&amp; cd vfs\n$ cat &lt;&lt; EOF &gt; hello-kernel.c\n#include &lt;stdio.h&gt;\n\nint main(){\n        printf(&quot;Hello, kernel!\\n&quot;);\n        sleep(9999999999999);\n}\nEOF\n$ gcc --static hello-kernel.c -o init\n$ find . | cpio -o -H newc | gzip &gt; root.cpio.gz\n\nMaking a hard disk (for root)\n$ dd if=/dev/zero of=roorfs.ext2 bs=1024k count=256\n$ mkfs.ext2 rootfs.ext2\n\nBooting\n# for booting hello-kernel\n$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage -nographic --append &quot;console=tty0 console=ttyS0 panic=1 root=/dev/sda rootfstype=ext2&quot; -hda rootfs.ext2 -m 1024 -vga none -display none -serial mon:stdio -no-reboot -initrd vfs/root.cpio.gz \n# for booting busybox\n$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage -nographic --append &quot;console=tty0 console=ttyS0 panic=1 root=/dev/sda rootfstype=ext2&quot; -hda rootfs.ext2 -m 1024 -vga none -display none -serial mon:stdio -no-reboot -initrd initrd/root.cpio.gz \n# qemu-system-x86_64 -kernel arch/x86_64/boot/bzImage -initrd vfs/root.cpio.gz -nographic --append &quot;console=tty0 console=ttyS0 panic=1&quot; -m 512 -vga none -d isplay none -serial mon:stdio -no-reboot\n# qemu-system-x86_64 -kernel arch/x86/boot/bzImage -initrd vfs/root.cpio.gz -nographic --append &quot;console=tty0 console=ttyS0 panic=1 root=/dev/sda&quot; -hda rootfs.ext2 -m 512 -vga none -display none -serial mon:stdio -no-reboot\n\nMy own init works now\nRunning the Kernel on Hardware\nIf you’re on ubuntu, you can do\n$ update-grub2 # make sure you&#039;re using the grub bootloader\n$ make modules_install\n$ make install\n\nWhen booting up, press and hold &lt;Shift&gt; to go to the grub menu, then go to advanced options to select the kernel you want to boot with.\n#Debugging the Kernel using GDB\nUsing instructions from here\nvim .config # edit some stuff\nmake -j32\nRunning time!\nqemu-system-x86_64 -gdb tcp::1234 -S # the rest of the stuff\nqemu-system-x86_64 -kernel arch/x86/boot/bzImage -nographic --append &quot;console=tty0 console=ttyS0 panic=1 root=/dev/sda rootfstype=ext2 nokaslr&quot; -hda rootfs.ext2 -m 1024 -vga none -display none -serial mon:stdio -no-reboot -initrd initrd/root.cpio.gz -gdb tcp::1234 -S\ntarget remote :1234\ncontinue\n\nUse ^C to SIGINT the kernel.\nInterrupting Startup\ntarget remote :1234\nhbreak start_kernel\ni b # info breakpoints\nc\n\nLooking at the proces struct\n(gdb) lx-ps                                               \n      TASK          PID    COMM    \n0xffffffff828169c0   0   swapper\n(gdb) p ((struct task_struct *) 0xffffffff828169c0)\n$11 = (struct task_struct *) 0xffffffff828169c0 &lt;init_task&gt;\n(gdb) p $11-&gt;pid\n$13 = 0\n\nInterrupts\nThe first impt thing to do is learn how to interrupts work\n(gdb) monitor info registers\n(gdb) set $idtr=0xfffffe0000000000\n(gdb) print /x *(uint64_t*)$idtr\n$15 = 0x81e08e00001008f0\n(gdb) define idt_entry\n&gt;set $tmp = *(uint64_t*)($idtr + 8 * $arg0)\n&gt;print (void *)(($tmp&gt;&gt;48&lt;&lt;16)|($tmp&amp;0xffff))\n&gt;end\n(gdb) set $i=0\n(gdb) idt_entry $i++\n\nSystem calls\nLet’s pay some attention to\nsyscalls_64.h and arch/x86/entry/syscall_64.c.\nThe syscall_64.c file generates code using extern.\nThe definition for the function is provided by the\nfs/read_write.c. Namely,\nSYSCALL_DEFINE3(lseek, unsigned int, fd, off_t, offset, unsigned int, whence)\n{\n\treturn ksys_lseek(fd, offset, whence);\n}\nPwn stuff\ngdb a.out\ndisassemble main\nr\nsi\nshow reg\n^x ^a # to open up TUI mode\nlayout next # use the assembly view\n\nBypassing license key\nbreak main\nr a\nni # until the 2nd jne\nset $eflags ^= (1&lt;&lt;6)\nc\n\nFormat string (stonks)\njust spam %x to print stuff on the stack\nBuffer Overflow (buffer overflow 1)\nIt seems like get_return_address() is an internal picoCTF function in asm.h source.\nUsing Radare2,\naaa\ns main\nood\npd\nVV p\ndc\n&lt;F7&gt; # to step \n. # to return to %rip\n\nCache me outside\nAttempting the picoctf challenge. Binary will not execute because it has the wrong libc"},"old-blogs-(jekyll)/2023-08-13-xv6":{"title":"Playing with xv6","links":[],"tags":[],"content":"I chose to do riscv today but doing x86 will probably be faster.\nCompiling the RISCV Toolchain\nWe need to do this to obtain riscv64-unknown-linux-gnu-gcc\ngit clone --depth 1 github.com/mit-pdos/xv6-riscv\ngit clone --depth 1 github.com/riscv-collab/riscv-gnu-toolchain\ncd riscv-gnu-toolchain\nsudo apt-get install autoconf automake autotools-dev curl python3 python3-pip libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev ninja-build git cmake libglib2.0-dev\n./configure --prefix=/opt/riscv\nsudo make linux # this takes forever\n\nCompiling QEMU\nWe need to do this to obtain qemu-system-riscv64\ngit clone --branch v5.0.0 --depth 1 github.com/qemu/qemu\ncd qemu\n./configure --target-list=riscv64-softmmu --disable-docs\nmake -j8\nsudo make install\n\nCompiling xv6\ncd ../xv6-riscv\nTOOLPREFIX=/opt/riscv/bin/riscv64-unknown-linux-gnu- make qemu\n\nIf all goes well, you should boot into a shell\nxv6 kernel is booting\n\nhart 1 starting\nhart 2 starting\ninit: starting sh\n$ \n$ ls\n.              1 1 1024\n..             1 1 1024\nREADME         2 2 2305\n\nTo exit qemu, press Ctrl-A X.\nDebugging xv6\nOptionally, run with gdb attached\nTOOLPREFIX=/opt/riscv/bin/riscv64-unknown-linux-gnu- make qemu-gdb\n\nThen, in another terminal, run\n/opt/riscv/bin/riscv64-unknown-linux-gnu-gdb\ntarget remote :26000 # or whatever port they said above\ncontinue\nCtrl-C # to send interrupt\nbreak swtch\nc\n# go back and type something in the shell\n\nPoking the kernel code\nsh.c Command Types\nI injected the following into sh.c.\n  struct pipecmd *pcmd;\n  struct redircmd *rcmd;\n  fprintf(2, &quot;tch is here, type = %d\\n&quot;, cmd-&gt;type);\n\n  if(cmd == 0)\n    exit(1);\n\nThen I recompiled using make qemu. The output is\n$ ls \ntch is here, type = 1\n... # rest of output\n\nIf we look at sh.c, we see that 1 corresponds to EXEC.\n#define EXEC  1\n#define REDIR 2\n#define PIPE  3\n#define LIST  4\n#define BACK  5\n\n\nEXEC is running any command\nREDIR is for redirecting output via &gt; to a file\nPIPE is for piping output via | to another program\nLIST is for a list of commands, separated by ;\nBACK is for running a command in the background using &amp;\n\nBalemarthy Part 5 talks about the implementation in detail.\nLet’s try to implement a few new features following this Harshal tutorial. We will do that in another post!"},"old-blogs-(jekyll)/2023-10-05-qemu":{"title":"Fun with QEMU Arguments and Character Devices","links":[],"tags":[],"content":"If you do man qemu-system and search for -serial you would come across a good explanation of how the qemu terminal emulation works. Let’s have abit of fun with it.\nPlaying with Character Devices\nqemu-system-x86_64 -kernel ./vmlinux \n\npops up a window with a few tabs, VGA, compat_monitor0, serial0, parallel0 (Ctrl-Alt M &gt; View &gt; Show Tabs)\n\nVGA is what you would see if you connected a monitor to the system you are booting up.\ncompat_monitor0 is the qemu monitor that you can use to interact with the qemu instance. (qemu). You can type help to see the commands you can use.\nserial0 and parallel0 are buses or channels of communication between the host and the emulated qemu instance. I like to think of parallel as the 64-bit bus and serial as RX/TX UART communication.\n\nqemu-system-x86_64 -kernel ./vmlinux -append &quot;console=ttyS0 meowmeow&quot;\n\nJust like how you can parse arguments into an executable like ./a.out param1 param2, you can also parse arguments into ./vmlinux (just that you can’t execute it directly and need to use qemu or boot it from a bootloader). In this case we pass an argument console=ttyS0 to tell the kernel to use ttyS0 as the console. We also pass meowmeow as an argument, which is just a random marker I will find in the kernel logs (when we log to a file). For now you see a lot of stuff spew out in the serial0 tab.\nYou could try other consoles too listed here. I tried putting a funny Baud rate but nothing happened.\nqemu-system-x86_64 -kernel ./vmlinux -append &quot;console=ttyS0&quot; -serial file:serial.log \ncat serial.log # see kernel boot logs\ncat serial.log | grep meowmeow\n[    0.000000] Command line: console=ttyS0 meowmeow\n[    0.058980] Kernel command line: console=ttyS0 meowmeow\n[    0.059534] Unknown kernel command line parameters &quot;meowmeow&quot;, will be passed to user space.\n\nYou can specify many -serial flags, it would correspond to serial0, serial1, etc. After each -serial, you specify a character device, which could be many things. In this example, we chose a write-only chardev which writes to a file. Read the man page or -chardev help to see all options.\nWe also observe that whatever we parse into -append gets sent to the kernel file vmlinux. So it comes as no surprise later we send things like console=ttyS0 panic=1 root=/dev/sda rootfstype=ext2. Basically just telling the kernel what to do when it panics and how to work with the emulated hardware we pass it.\nqemu-system-x86_64 -kernel ./vmlinux -append &quot;console=ttyS0&quot; -serial file:serial.log -chardev file,path=mon.log,mux=on,id=char0 -mon chardev=char0,mode=readline\n\nThis binds the file mon.log to the qemu monitor. When we open it up, we see\n$ cat mon.log\nQEMU 4.2.1 monitor - type &#039;help&#039; for more information\n(qemu)\n\nPractically speaking, it doesn’t make sense to bind a monitor interactive console to a write-only file. So let’s bind it to stdio instead.\nqemu-system-x86_64 -chardev stdio,id=char0 -mon chardev=char0,mode=readline -kernel ./vmlinux -append &quot;console=ttyS0&quot;\n\nIn the graphical window, open the serial0 tab. Then in the monitor, you can play around\n(qemu) info chardev\nparallel0: filename=vc\nchar0: filename=stdio\nserial0: filename=vc\n(qemu) system_reset\n(qemu) stop\n(qemu) cont\n\nIf you don’t like the kernel logs to appear in graphical window, you can bind -serial chardev:char0 too. Now you can cycle between compat-monitor0 and serial0 using C-A C.\nIf we do this to -parallel 0 (which is currently blank anyway), and also do -display none. Then we have effectively done -nographic ourselves using:\nNOGRAPHIC=&quot;-chardev stdio,mux=on,id=char0 -mon chardev=char0,mode=readline -serial chardev:char0 -parallel chardev:char0 -display none&quot;\n\nHere are some differences, but please DO NOT use $NOGRAPHIC because I found it causes later issues with the shell (busybox segfault). Just use -nographic and treat $NOGRAPHIC like an academic curiosity.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-nographic$NOGRAPHICmesses up wrapping (fixed with reset)doesn’tprints VGA stuff to console (“Booting from ROM”)doesn’tworks with shelldoesn’t (OH NO BAD)\nYou can have abit more fun here with some automation.\nTrying to Boot\nqemu-system-x86_64 -nographic -kernel ./vmlinux -append &quot;console=ttyS0&quot;\n\nAnyway, enough playing with chardevs and terminals, we see that the kernel is looking for a blockdev root device\n[    1.332198] /dev/root: Can&#039;t open blockdev\n[    1.332485] VFS: Cannot open root device &quot;(null)&quot; or unknown-block(0,0): error -6\n[    1.332612] Please append a correct &quot;root=&quot; boot option; here are the available partitions:\n[    1.332827] 0b00         1048575 sr0 \n\nSo let’s try to add a root device\ndd if=/dev/zero of=rootfs.ext2 bs=1024k count=256\nmkfs.ext2 rootfs.ext2\nqemu-system-x86_64 -nographic -kernel ./vmlinux -append &quot;console=ttyS0 root=/dev/sda&quot; -hda rootfs.ext2\n\nYou can pass in more drives using -hda, -hdb, -hdc, -hdd. But it will fill up /dev/sda,sdb,sdc,sdd sequentially. Then\n(qemu) info block\n\nIt still crashes, but now it complains there is no init.\nKernel panic - not syncing: No working init found.  Try passing init= option to kernel. See Linux Documentation/admin-guide/init.rst for guidance.\n\nLet’s try writing out own init to get a feel for what the kernel wants.\n$ mkdir vfs &amp;&amp; cd vfs\n$ cat &lt;&lt; EOF &gt; hello-kernel.c\n#include &lt;stdio.h&gt;\n\nint main(){\n        printf(&quot;Hello, kernel!\\n&quot;);\n        sleep(9999999999999);\n}\nEOF\n$ gcc --static hello-kernel.c -o init\n$ find . | cpio -o -H newc | gzip &gt; root.cpio.gz\n$ qemu-system-x86_64 -nographic -kernel ./vmlinux -append &quot;console=ttyS0 root=/dev/sda&quot; -hda rootfk.ext2 -initrd vfs/root.cpio.gz \n\nThis shows\n[    1.504610] Run /init as init process\nHello, kernel!\n\nYay! If you have segmentation fault after typing, make sure you are using -nographic (instead of my $NOGRAPHIC) because I think when you do your own multiplexing it confuses qemu (probably a bug, would be interesting to investigate).\nInterestingly, if we have an -initrd we actually don’t need a -hda. We can just do\nqemu-system-x86_64 -kernel ./vmlinux -append &quot;console=ttyS0&quot; -initrd vfs/root.cpio.gz\n\nit works fine too. Instead of using our own init, we can use busybox’s init. Check out my minimal kernel blog for details.\nAnyway, the main purpose of this blog was to document my understanding of character devices and the many qemu parameters, so I will stop here. Hope you found it useful! Contact me at telegram @tch1001 if you need any help!"},"old-blogs-(jekyll)/2023-12-28-aws-lambda-bash":{"title":"Custom Binaries on AWS Lambda + Poking Around (Bonus)","links":[],"tags":[],"content":"AWS Lambda is a serverless computing platform that allows you to run code without provisioning or managing servers. It is a great way to run code without having to worry about the underlying infrastructure. It is also very cheap, and you only pay for the time your code is running.\nIf your workload is a simple script, you can use their inline editor to write your code. But if you want to use a custom binary, you need to package it into a zip file and upload it to AWS Lambda. This is a guide on how to do that.\nIn my example, I will upload a binary that I compiled from source. I will not be using the CLI and will be using the AWS Web Console instead.\nCreating the Lambda Function\nFirst create a Lambda function. I will be using the Amazon Linux 2 runtime. I will also be using the default execution role.\n\nSelect Amazon Linux 2\n\nWe will now be uploading a bootstrap file in the next section\n\nWhen the function has finished creating, the Code dashboard will look like this\n\nThe README.md file reads\nA runtime is a program that runs a Lambda function&#039;s handler method when the function is invoked. The runtime can be included in your function&#039;s deployment package, or in a [layer](docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html). [Learn more](docs.aws.amazon.com/lambda/latest/dg/runtimes-custom.html) about custom Lambda runtimes.\n\nFor reference, this function includes a sample [Bash](www.gnu.org/software/bash/) runtime in `bootstrap.sample` and a corresponding handler file `hello.sh.sample`. As a next step, you should provide your own bootstrap by either adding a layer implementing a custom runtime or including a `bootstrap` file in this function&#039;s deployment package.\n\nWe may be tempted to just rename the function bootstrap.sample to bootstrap and the function hello.sh.sample to hello.sh.\n\nThen create a new test event and run it.\n\nWe should see a successful test.\n\nCommon Error: Creating a new file instead of renaming\nIf you create a new file instead of renaming, you will see this error\n\nCommon Error: Not deploying the function\nAfter you make changes to the files (including renaming), you need to deploy the function. Otherwise the old files will still be used. And they will say they cannot find the bootstrap file.\n\nCommon Error: I accidentally deleted the bootstrap file\nIf you accidentally deleted the old bootstrap.sh.sample file, and now you can’t create one that has executable permissions, you must do the following\ncat &gt; bootstrap &lt;&lt; EOF\n#!/bin/sh\nset -euo pipefail\n\n# Handler format: &lt;script_name&gt;.&lt;bash_function_name&gt;\n#\n# The script file &lt;script_name&gt;.sh  must be located at the root of your\n# function&#039;s deployment package, alongside this bootstrap executable.\nsource $(dirname &quot;$0&quot;)/&quot;$(echo $_HANDLER | cut -d. -f1).sh&quot;\n\nwhile true\ndo\n    # Request the next event from the Lambda runtime\n    HEADERS=&quot;$(mktemp)&quot;\n    EVENT_DATA=$(curl -v -sS -LD &quot;$HEADERS&quot; -X GET &quot;http://${AWS_LAMBDA_RUNTIME_API}/2018-06-01/runtime/invocation/next&quot;)\n    INVOCATION_ID=$(grep -Fi Lambda-Runtime-Aws-Request-Id &quot;$HEADERS&quot; | tr -d &#039;[:space:]&#039; | cut -d: -f2)\n\n    # Execute the handler function from the script\n    RESPONSE=$($(echo &quot;$_HANDLER&quot; | cut -d. -f2) &quot;$EVENT_DATA&quot;)\n\n    # Send the response to Lambda runtime\n    curl -v -sS -X POST &quot;http://${AWS_LAMBDA_RUNTIME_API}/2018-06-01/runtime/invocation/$INVOCATION_ID/response&quot; -d &quot;$RESPONSE&quot;\ndone\nEOF\n\ncat &gt; hello.sh &lt;&lt; EOF\nfunction handler () {\n    EVENT_DATA=$1\n\n    RESPONSE=&quot;{\\&quot;statusCode\\&quot;: 200, \\&quot;body\\&quot;: \\&quot;Hello from Lambda!\\&quot;}&quot;\n    echo $RESPONSE\n}\nEOF\n\nChange the permissions\nchmod +x bootstrap\nchmod +x hello.sh\n\nThen zip it up and upload it\nzip my_bootstrap.zip bootstrap hello.sh\n\n\n\n\nCustom Binary\nDo note that whatever scripts or binaries you want to run, you need to compile it on the same OS as the Lambda runtime. In this case, it is Amazon Linux 2. So I will be using a Docker container to compile my binary.\nDocker Container\nFirst setup our build environment. By looking at our runtime image, we can refer to the docs to find the Dockerfile for the image.\n\nWhich we can find the image for here\n\nWe go ahead and clone the repo\ngit clone --branch provided.al2 --depth 1 github.com/aws/aws-lambda-base-images.git \ncd aws-lambda-base-images\n# either of the following\nsed -i &#039;s/scratch/public.ecr.aws\\/lambda\\/nodejs:18/g&#039; Dockerfile.provided.al2\nsed -i &#039;s/scratch/amazonlinux:2/g&#039; Dockerfile.provided.al2\ndocker build -f Dockerfile.provided.al2 -t lambda_image:1.0.0 .\n\nWe had to replace the FROM scratch with FROM public.ecr.aws/lambda/nodejs:18 because we want to docker exec into the container later and have a nice shell, and scratch does not have a shell. Also because it seems like we can’t run /lambda-entrypoint.sh the scratch image (either this is bug in Amazon’s GitHub, or Lambda loads containers differently from our local Docker runc).\nCreating our image\nThen we can run our build environment\ndocker run -d -v $PWD:/tmp/meow --name lambda_image lambda_image:1.0.0\ndocker exec -it lambda_image bash\n\nWriting our binary\nInstall build environment in the interative shell\nyum install -y gcc-c++ vim\n\nOr you could bake it into the image by adding it to the Dockerfile\nCompiling our binary\nThen we can write a simple C++ program\ncat &gt; test.cpp &lt;&lt; EOF\n#include &lt;stdio.h&gt;\nint main(){\n    printf(&quot;Hello, world!\\n&quot;);\n}\nEOF\n\nAnd compile it\ng++ test.cpp -o my_binary\ncp my_binary /tmp/meow\n\nExit the container and zip it up\nchmod +x my_binary\nzip my_binary.zip my_binary\n\nUploading our binary\nThen we can upload it to our Lambda function\n\nWe use hello.sh to make sure it works\n\nThe output is\ntotal 8\n-rwxr-xr-x 1 root root 8176 Dec 27 18:01 my_binary\nHello, world!\n\nExtra: Understanding AWS Lambda Runtime\nNice that you are here at the end! Let’s have some fun and dig deep into AWS Lambda.\ndocker exec -it --entrypoint bash lambda_image:1.0.0 \ncat /lambda-entrypoint.sh\n\nWe see that\n#!/bin/sh\n# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n\nif [ $# -ne 1 ]; then\n  echo &quot;entrypoint requires the handler name to be the first argument&quot; 1&gt;&amp;2\n  exit 142\nfi\nexport _HANDLER=&quot;$1&quot;\n\nRUNTIME_ENTRYPOINT=/var/runtime/bootstrap\nif [ -z &quot;${AWS_LAMBDA_RUNTIME_API}&quot; ]; then\n  exec /usr/local/bin/aws-lambda-rie $RUNTIME_ENTRYPOINT\nelse\n  exec $RUNTIME_ENTRYPOINT\nfi\n\nCuriously,\ncat /usr/local/bin/aws-lambda-rie # binary file garbage\ncat /var/runtime/bootstrap \n\nWe see\n#!/bin/sh\n# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n\nif [ -z &quot;$NODE_PATH&quot; ]; then\n  nodejs_mods=&quot;/opt/nodejs/node_modules&quot;\n  nodejs18_mods=&quot;/opt/nodejs/node18/node_modules&quot;\n  runtime_mods=&quot;/var/runtime/node_modules&quot;\n  task=&quot;/var/runtime:/var/task&quot;\n  export NODE_PATH=&quot;$nodejs18_mods:$nodejs_mods:$runtime_mods:$task&quot;\nfi\n\nif [ -n &quot;$AWS_LAMBDA_FUNCTION_MEMORY_SIZE&quot; ]; then\n  new_space=$(expr $AWS_LAMBDA_FUNCTION_MEMORY_SIZE / 10)\n  semi_space=$(expr $new_space / 2)\n  old_space=$(expr $AWS_LAMBDA_FUNCTION_MEMORY_SIZE - $new_space)\n  MEMORY_ARGS=(\n    &quot;--max-semi-space-size=$semi_space&quot;\n    &quot;--max-old-space-size=$old_space&quot;\n  )\nfi\n\n# If NODE_EXTRA_CA_CERTS is being set by the customer, don&#039;t override. Else, include RDS CA\nif [ -z &quot;${NODE_EXTRA_CA_CERTS+set}&quot; ]; then\n  # Use the default CA bundle in CN regions and regions that have 3 dashes in their name\n  if [ &quot;${AWS_REGION:0:3}&quot; == &quot;cn-&quot; ] || [ &quot;${AWS_REGION//[^-]}&quot; == &quot;---&quot; ]; then\n    export NODE_EXTRA_CA_CERTS=/etc/pki/tls/certs/ca-bundle.crt\n  else\n    # /var/runtime/ca-cert.pem contains all certs in &quot;/etc/pki/tls/certs/ca-bundle.crt&quot; that\n    # are not already embedded in the node binary.\n    export NODE_EXTRA_CA_CERTS=/var/runtime/ca-cert.pem\n  fi\nfi\n\nexport AWS_EXECUTION_ENV=AWS_Lambda_nodejs18.x\n\nNODE_ARGS=(\n    --expose-gc\n    --max-http-header-size 81920\n    &quot;${MEMORY_ARGS[@]}&quot;\n    /var/runtime/index.mjs\n    )\n\nif [ -z &quot;$AWS_LAMBDA_EXEC_WRAPPER&quot; ]; then\n  exec /var/lang/bin/node &quot;${NODE_ARGS[@]}&quot;\nelse\n  wrapper=&quot;$AWS_LAMBDA_EXEC_WRAPPER&quot;\n  if [ ! -f &quot;$wrapper&quot; ]; then\n    echo &quot;$wrapper: does not exist&quot;\n    exit 127\n  fi\n  if [ ! -x &quot;$wrapper&quot; ]; then\n    echo &quot;$wrapper: is not an executable&quot;\n    exit 126\n  fi\n    exec -- &quot;$wrapper&quot; /var/lang/bin/node &quot;${NODE_ARGS[@]}&quot;\nfi\n\nIt seems to be invoking nodejs. I wonder if other images will have different bootstrap files. Let’s go to the Amazon Lambda console and use hello.sh to probe around.\nWith my hello.sh file as\nfunction handler () {\n    ls -l /var/runtime\n}\n\nI get a funny result that\ntotal 9852\n-rwxr-xr-x 1 root root 10085351 Oct 19 17:20 init\n\nI tried to cat it but it timed out (since it’s 10Mb afterall).\nWhere is layers uploaded to?\nAWS Lambda Layers are uploaded to /opt in the container. We can verify this by creating a layer and uploading it to our function.\necho &quot;meow&quot; &gt; test.txt\nzip test.zip test.txt\n\nThen after uploading, we can use hello.sh to again probe around.\nfunction handler () {\n    ls -l /opt\n}\n\nand we see\ntotal 1\n-rwxr-xr-x 1 root root 5 Dec 27 17:37 test.txt\n\nNow what if we wanted to upload it to a different path? Idk\nEnvironment variables\nI used env in hello.sh to see the environment variables. I redacted some of the values.\nAWS_LAMBDA_FUNCTION_VERSION=$LATEST\nAWS_SESSION_TOKEN=REDACTED\nLAMBDA_TASK_ROOT=/var/task\nAWS_LAMBDA_LOG_GROUP_NAME=/aws/lambda/custom_runtime\nLD_LIBRARY_PATH=/lib64:/usr/lib64:/var/runtime:/var/runtime/lib:/var/task:/var/task/lib:/opt/lib\nAWS_LAMBDA_RUNTIME_API=127.0.0.1:9001\nAWS_LAMBDA_LOG_STREAM_NAME=2023/12/27/[$LATEST]REDACTED_UUID\nAWS_LAMBDA_FUNCTION_NAME=custom_runtime\nAWS_XRAY_DAEMON_ADDRESS=REDACTED_IPV4_ADDRESS:2000\nPATH=/usr/local/bin:/usr/bin/:/bin:/opt/bin\nAWS_DEFAULT_REGION=us-east-1\nPWD=/var/task\nAWS_SECRET_ACCESS_KEY=REDACTED\nLANG=en_US.UTF-8\nLAMBDA_RUNTIME_DIR=/var/runtime\nAWS_LAMBDA_INITIALIZATION_TYPE=on-demand\nTZ=:UTC\nAWS_REGION=us-east-1\nAWS_ACCESS_KEY_ID=REDACTED\nSHLVL=1\n_AWS_XRAY_DAEMON_ADDRESS=REDACTED_IPV4_ADDRESS\n_AWS_XRAY_DAEMON_PORT=2000\nAWS_XRAY_CONTEXT_MISSING=LOG_ERROR\n_HANDLER=hello.handler\nAWS_LAMBDA_FUNCTION_MEMORY_SIZE=128\n_=/usr/bin/env\n"},"old-blogs-(jekyll)/2024-01-07-renormalization":{"title":"Reviewing Renormalization Resources (in QFT)","links":[],"tags":[],"content":"There are many resources on renormalization in Quantum Field Theory (QFT). I have been reading a few of them and I will review them here. This is roughly in the order I recommend reading them (as a complete beginner), with the first few being the best.\nFind my recommended reading order below.\nNote this blog doesn’t cover renormalization group and solid state physics. I will cover that in a separate post. The focus here is QFT.\nZee QFT\nAnthony Zee’s textbook Quantum Field Theory in a Nutshell Part III Renormalization has great exposition. I especially like the dialogue between the experimentalist and the theorist.\nIt is worth mentioning Zee’s Lectures although it is abit blurry.\nChap III.1: Conceptual\nIn \\phi^4 theory, 2 particle scattering up to 1 loop with hard cutoff \\Lambda:\n\\mathcal{M}(s,t,u,\\Lambda,\\lambda)=-i \\lambda+i C \\lambda^2\\left[\\log \\left(\\frac{\\Lambda^2}{s}\\right)+\\log \\left(\\frac{\\Lambda^2}{t}\\right)+\\log \\left(\\frac{\\Lambda^2}{u}\\right)\\right]+O\\left(\\lambda^3\\right)\n(equation 2)\nZee then explains that we can measure \\mathcal{M} at momenta s_0, t_0, u_0, and we call that \\lambda_P := \\mathcal{M}(s_0,t_0,u_0, \\Lambda, \\lambda). To make sure that \\lambda_P is independent of \\Lambda, Zee says that \\lambda(\\Lambda) must satisfy\n\\Lambda \\frac{d \\lambda}{d \\Lambda}=6 C \\lambda^2+O\\left(\\lambda^3\\right)\n(equation 16)\nWhat I especially like about Zee’s exposition is that he writes out the full derivation for how to invert \\lambda_P(\\lambda) to get \\lambda(\\lambda_P) (equation 7). This is something that is often glossed over in other lectures. Although it is just 2 lines, it is not a common procedure at all, and I think it is important to see it done explicitly the first time.\n\\begin{aligned}\n\\mathcal{M}&amp;=-i \\lambda+i C \\lambda^2 L+O\\left(\\lambda^3\\right) \\\\\n-i \\lambda_P&amp;=-i \\lambda+i C \\lambda^2 L_0+O\\left(\\lambda^3\\right) \\\\\n-i \\lambda&amp;=-i \\lambda_P-i C \\lambda^2 L_0+O\\left(\\lambda^3\\right)\\\\\n&amp;=-i \\lambda_P-i C \\lambda_P^2 L_0+O\\left(\\lambda_P^3\\right)\n\\end{aligned}\n(equations 5-7)\nWe then substitute \\lambda(\\lambda_P) back into \\mathcal{M} to get\n\\begin{aligned}\n\\mathcal{M}&amp;=-i \\lambda+i C \\lambda^2 L+O\\left(\\lambda^3\\right)\\\\\n&amp;=-i \\lambda_P-i C \\lambda_P^2 L_0+i C \\lambda_P^2 L+O\\left(\\lambda_P^3\\right) \\\\\n&amp;= -i \\lambda_P+i C \\lambda_P^2\\left[\\log \\left(\\frac{s_0}{s}\\right)+\\log \\left(\\frac{t_0}{t}\\right)+\\log \\left(\\frac{u_0}{u}\\right)\\right]+O\\left(\\lambda_P^3\\right)\n\\end{aligned}\n(equation 9)\nAs Nabil Iqbal puts it, “you want to relate measureable quantities to the measureable quantities”, like pressure to temperature.\nZee then covers Pauli-Villars regularization, and dimensional regularization in the Appendix of Chapter III.1.\nChap III.2: Renormalizable vs Non-renormalizable (using Dimensional Analysis)\nZee covers it quite well. I especially like his example of a vector boson theory being the UV completion of Fermi theory (equation 1, page 157).\nChap III.3: Counterterms and Physical Perturbation Theory\nI’ll be honest I don’t really like his explanation of mass renormalization that much.\nChap III.7: Polarizing the Vacuum and Renormalizing the Charge\nNo comments\nNabil Iqbal Lectures\nNabil Iqbal Lectures from QFT2 at Durham.\nLecture 3d: Intro to Renormalization\nHe mentions the problem of infinity if we take the limit \\Lambda \\rightarrow \\infty in the \\phi^4 theory.\n2:59 I especially like his analogy of ideal gas law and how we relate 2 observable things to each other.\n7:10 I also like that he explicitly says that \\lambda_P \\equiv i\\mathcal{M}(s_0,t_0,u_0) is a definition. In Zee’s book, he says \\lambda_P is measured, but doesn’t explicitly say that it is definitionally equal to \\mathcal{M}(s_0,t_0,u_0), and it must instead be inferred by looking at the equations 3-4.\n10:20 He inverts \\lambda_P(\\lambda) to get \\lambda(\\lambda_P), but leaves it to the viewer to verify. I prefer Zee for the explicit working in this regard.\nLecture 4a: Renormalized Perturbation Theory\nTo be honest, I don’t like this lecture that much. He explains the renormalization conditions (pole of 2-point function at p^2 = m^2 must have residue 1).\nHe derives the same result\ni \\mathcal{M}\\left(s, t, u\\right)=-i \\lambda+\\frac{i \\lambda^2}{32 \\pi^2} \\left[ \\log \\left(\\frac{s_0}{s}\\right)+\\log \\left(\\frac{t_0}{t}\\right)+\\log \\left(\\frac{u_0}{u}\\right) \\right]\n(equation at 18:12)\nusing counterterms and renormalization conditions.\nLecture 4b: Renormalization of the two-point function\nNo comments\nLecture 4c: Which Theories Are Renormalizable\nNo comments\nLecture 4d: non-renormalizable theories\nI like the examples he introduced.\nTobias Osborne Lectures\nTobias Osborne Lectures from his Advanced QFT Series. Tobias approaches renormalization in a very philosophical manner. He covers \\phi^4 theory.\nLecture 8: Philosophy of Renormalization\nHe spends a good 40 minutes talking about philosophy of physics. I especially like 56:00 where he says we can declare victory even if the (bare) parameters of our theory are not necessarily observables, and they can totally depend on a cut-off \\Lambda, and he labels them z_i(\\Lambda) to emphasise it. My takeaway is that the unrenormalized/bare parameters are merely a means to an end, and the end is to predict observables.\nLecture 9: Renormalization of \\phi^4 theory\nNo comments\nLancaster QFT\nQuantum Field Theory for the Gifted Amateur Part VIII Renormalization. He introduces renormalization using counterterms first, then explaining the philosophy of “what is physically observable”, mirroring the historical development of renormalization.\nI think the historical way is not a good way to learn it though. I much rather learn it from the modern perspective of effective field theory first, and then learn the historical development. This is because physicists were confused about renormalization for a long time, before a drastic change in perspective made it clearer. It would thus make more sense to use the benefit of hindsight when teaching renormalization.\nChap 31: Quasiparticles\nI don’t really like the explanations here.\nChap 32: Renormalization\nHe works with \\phi^4 theory. While I like that he covers a lot of detailed mathematical steps, I don’t really like the explanations here. This is a useful resource if you are already familiar with the conceptual understanding and wish to revise it.\nChap 33: Propagators and Feynman Diagrams\nI somewhat like his derivation of mass renormalization, as well as renormalization conditions for counterterms.\nChap 34 &amp; 35: Renormalization Group\nI like his use of examples, especially examples in solid state physics.\n Detailed Calculations \nFrom here onwards, the resources are more detailed and less conceptual. They are good if you already know the conceptual idea and want to apply it to real calculations.\nLewis Ryder QFT\nLewis Ryder’s textbook Quantum Field Theory writes mostly about renormalization of gauge theories in Chapter 9. This is good if you already have a decent conceptual understanding of renormalization and want to see how it works in phenomenology.\nRicardo D. Matheus Lectures\nQFT2 from IFT UNESP (Sao Paulo) is a great series if you want to dive into QED and QCD calculations in gory detail. I especially like his Kallen-Lehmann Lecture and his LSZ Lecture.\nwky54321 Lecture (Summary)\nRenormalization of QED is a standalone lecture summarising QED calculations. I think the first half is good for beginners, but the back half is hard to follow if you didn’t already know the material.\nFrancois David Lectures\nFrancois David Lectures from QFT2 at Saclay.\nAshoke Sen Lectures\nAshoke Sen Lectures from QFT2\n Recommended Reading Order \nIf you are completely new to renormalization, I recommend the following resources in this order:\nConceptual Understanding / Vertex Renormalization\n\nZee QFT Chapter III.1 (Conceptual)\nZee QFT Chapter III.2 (Dimensional Analysis)\nNabil Iqbal Lecture 3d (Intro to Renormalization)\nTobias Osborne Lecture 8 (Philosophy of Renormalization)\nTobias Osborne Lecture 9 (Dimensional Analysis)\n\nCounterterms and Renormalization Conditions\n\nLancaster QFT Chap 32 (Renormalization)\n\nMass Renormalization\n\nidk, I don’t like any of the explanations so far\n"}}